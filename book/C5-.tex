\documentclass[DynamicalBook]{subfiles}
\begin{document}
%


\setcounter{chapter}{4}%Just finished 3.


%------------ Chapter ------------%
\chapter{Behaviors of the whole from behaviors of the parts}\label{chapter.5}

%-------- Section --------%
\section{Introduction}

Let's take stock of where we've been so far in the past couple chapters.
\begin{itemize}
  \item In \cref{sec.deterministic_system}, we saw the definitions of
    \emph{deterministic systems} and \emph{differential systems}.
  \item In \cref{sec.wiring_sytems_discrete}, we learned about \emph{lenses}. We saw how systems can be
    interpreted as special sorts of lenses, and how we can wire together systems
    using lens composition.
  \item In \cref{sec.non_deterministic_systems} we learned about various sorts
    of \emph{non-deterministic systems}.
  \item In \cref{sec.behavior_discrete}, we learned about behaviors and \emph{charts}. We saw
    how to define behaviors of systems using the notion of chart. Finally, we
    gave a formal definition of \emph{theory of dynamical systems}, systematizing
    the various different notions --- discrete, differential, non-deterministic
    --- of dynamical systems. 
\end{itemize}

The two sorts of composition we have seen so far --- lens composition and chart
composition --- mirror the two sorts of composition at play in systems theory:
\begin{itemize}
  \item We can compose \emph{systems} by wiring them together. This uses lens composition.
  \item We can compose \emph{behaviors} of systems like we compose functions.
    This uses chart composition.
\end{itemize}

In this chapter, we will see how these two sorts of composition interact. In
short, behaviors of component systems give rise to behaviors of composite
systems. The way that behaviors of the whole arise from behaviors of the parts
is called \emph{compositionality}. In this chapter, we will prove a general
compositionality theorem concerning any sort of behavior in any systems theory.

But the behaviors of the component systems must be compatible with
eachother: if a system $\Sys{S_1}$ has its parameters set by the exposed
variables of a system $\Sys{S_2}$, then a behavior $\phi_1$ of $\Sys{S_1}$ will be
compatible with a behavior $\phi_2$ of $\Sys{S_2}$ when $\phi_2$ is a behavior
for the parameters charted by the variables exposed by $\phi_1$.

We will see that, remarkably, the way behaviors of composite systems arise from
behaviors of component systems (including the constraints of compatibility) are
described by a ``matrix arithmetic for sets''. From a lens we will construct a
``matrix of sets''; multiplying the ``vector of behaviors'' of the component
systems (indexed by their
charts) by this matrix yields the vector of behaviors of the composite. We begin this chapter with a
section explaining this idea in detail for steady states of deterministic
systems.

We have in fact already developed most of the important definitions --- doubly indexed category and lax doubly indexed functor --- and proven most of the crucial lemmas we need for this
result in \cref{sec.behaviors_general}. In this chapter, we will then construct \emph{representable doubly indexed
  functors} which will organize the various facts concerning the
compositionality of any sort of behavior in any systems theory.



%---- Section ----%
\section{Steady states compose according to the laws of matrix arithmetic}\label{sec.steady_states_matrix_arithmetic}


We have seen how we can compose systems, and we have seen how systems behave. We
have seen a certain composition of behaviors, a form of transitivity that says
that if we have a $\Sys{T}$-shaped behavior in $\Sys{S}$ and a $\Sys{S}$-shaped
behavior in $\Sys{U}$, then we get a $\Sys{T}$-shaped behavior in $\Sys{U}$. But what's the relationship between composing systems and composing their behaviors?

In this section we will give a
taste by showing how steady states compose. Later, in \cref{sec.representables}, we will see a very abstract
theorem that generalizes what we do here for steady states in the deterministic
systems theory to something that works for \emph{any sort of behavior} in \emph{any systems theory}.
But in order for that abstract theorem to make sense, we should first see the concrete
case of steady states in detail.  

Recall that the chart of a steady state $s \in \State{S}$ is the pair
$\lens{i}{o}$ with $o = \expose{S}(s)$ and $\update{S}(s, i) = s$. The set of all
possible charts for steady states is therefore $\In{S} \times \Out{S}$, and for
every chart $\lens{i}{o}$ we have the set $\Set{Steady}_{\Sys{S}}\lens{i}{o}$ of
steady states for this chart. 

We can see this function $\Set{Steady}_{\Sys{S}} : \In{S} \times \Out{S} \to \smset$ as a
\emph{matrix of sets} with $\Set{Steady}_{\Sys{S}}\lens{i}{o}$ in the row $i$
and column $o$. For example, consider system $\Sys{S_1}$ of
\cref{ex.wiring_transition_diagrams}:
\begin{equation}\label{eqn.wiring_transition_diagrams_steady_diag1}
\Sys{S_1} \coloneqq \begin{tikzpicture}[baseline=(Center)]
  \coordinate (Center) at (0,0);
	\node[draw] {
  \begin{tikzcd}[column sep=small]
    \LMOO{\const{s_{11}}}{\Blue} \ar[loop left, "\const{false}"] \ar[rr, bend left, "\const{true}"] \ar[dd, leftarrow, bend right, "\true"'] &  & \LMOO{\const{s_{12}}}{\Red} \ar[loop right, "\true"] \ar[dd, bend left, "\const{false}" ]\\
    & & \\
    \LMOO{\const{s_{13}}}{\Blue} \ar[loop left, "\false"] \ar[rr, leftarrow, bend left, "\false"] \ar[rr, leftarrow, bend right, "\true"'] & & \LMOO{\const{s_{14}}}{\Green}
  \end{tikzcd}
  };
\end{tikzpicture}
\end{equation}
This has output value set $\Set{Colors} = \{\Blue, \Red, \Green\}$ and input
parameter set $\Set{Bool} = \{\true, \false\}$. Here is its $(\Set{Colors}
\times \Set{Bool})$ steady state matrix:
\begin{equation}\label{eqn.steady_state_matrix1}
 \Set{Steady}_{\Sys{S_1}} =
  \kbordermatrix{
    & \Blue & \Red & \Green \\
    \true & \emptyset & \left\{ \begin{tikzcd} \LMOO{\const{s_{12}}}{\Red} \ar[loop right,
        "\true"]\end{tikzcd} \right\}  & \emptyset \\
    \false & \left\{ \begin{tikzcd} \LMOO{\const{s_{11}}}{\Blue} \ar[loop left,
        "\false"] \end{tikzcd}, \begin{tikzcd} \LMOO{\const{s_{13}}}{\Blue} \ar[loop left,
        "\false"] \end{tikzcd} \right\} & \emptyset & \emptyset
}    
\end{equation}
If we just want to know how many $\lens{i}{o}$-steady states there are, and not
precisely which states they are, we can always take the cardinality of the sets
in our matrix of sets to get a bona-fide matrix of numbers. Doing this to the
above matrix gives us the matrix
 \[\kbordermatrix{
    & \Blue & \Red & \Green \\
    \true & 0 & 1 & 0 \\
    \false & 2 & 0 & 0
}    
\]

Now, let's take a look at system $\Sys{S_2}$ from the same exercise:
\[
\Sys{S_2} \coloneqq \begin{tikzpicture}[baseline=(bl)]
	\node[draw] (bl) {
  \begin{tikzcd}[column sep=small]
    \LMOO{\const{s_{21}}}{\true} \ar[out=120, in=90, loop, red] \ar[in=210, out=250, loop, blue] \ar[rr, bend left = 10, dgreen] \ar[rr, leftarrow, red, bend right= 10] \ar[ddr, leftarrow, dgreen, bend right= 10] &  & \LMOO{\const{s_{22}}}{\false} \ar[loop right, dgreen] \ar[ddl, blue, bend left= 10] \ar[ddl,red, leftarrow, bend right= 10]  \\
    & & \\
    & \LMOO{\const{s_{23}}}{\true} \ar[out=300, in=240, loop, blue] & 
  \end{tikzcd}
  };
\end{tikzpicture}
\]

This has steady state matrix:
\begin{equation}\label{eqn.steady_state_matrix2}
  \Set{Steady}_{\Sys{S_2}} = \kbordermatrix{
    & \true & \false \\
    \Blue & \left\{ \begin{tikzcd} \LMOO{\const{s_{21}}}{\true}  \ar[ loop left,
        blue] \end{tikzcd}, \begin{tikzcd}\LMOO{\const{s_{23}}}{\true} \ar[loop left,
        blue] \end{tikzcd}\right\} & \emptyset \\
    \Red & \left\{ \begin{tikzcd} \LMOO{\const{s_{21}}}{\true} \ar[loop left,
        red] \end{tikzcd} \right\}& \emptyset \\
    \Green & \emptyset & \left\{ \begin{tikzcd} \LMOO{\const{s_{22}}}{\false} \ar[loop left,
        dgreen]
      \end{tikzcd} \right\}
}
\end{equation}
Or, again, if we just want to know how many steady states there are for each
chart:
\[
  \Set{Steady}_{\Sys{S_2}} = \kbordermatrix{
    & \true & \false \\
    \Blue & 2 & 0 \\
    \Red & 1 & 0 \\
    \Green & 0 & 1
}
\]

We can wire these systems together to get a system $\Sys{S}$:
\[
\Sys{S} \coloneqq 
\begin{tikzpicture}[oriented WD, bbx = .3cm, bby =.3cm, bb min width=.5cm, bb port length=2pt, bb port sep=1, every fit/.style={inner xsep=\bbx, inner ysep=\bby}
, baseline=(Outer.center)]
  \node[bb={1}{1}, fill=blue!10] (S1) {$\Sys{S_1}$};
  \node[bb={1}{1}, fill=blue!10, right= of S1] (S2) {$\Sys{S_2}$};

  \node[bb={1}{1}, fit={(S1) (S2)}] (Outer) {};

  \draw (Outer_in1) to (S1_in1);
  \draw (S1_out1) to (S2_in1);
  \draw (S2_out1) to (Outer_out1);
\end{tikzpicture}
\]

With just a bit of thought, we can find the steady states of this systems without fully calculating its
dynamics. A state of $\Sys{S}$ is a pair of states $s_1 \in  \State{S_1}$ and
$s_2 \in \State{S_2}$, so for it to be steady both its constituent states must be steady.
So let $\lens{i}{o} : \lens{\ord{1}}{\ord{1}} \tto
\lens{\Set{Bool}}{\Set{Bool}}$ be a chart for $\Sys{S}$ --- a pair of booleans.
We need $s_1$ and $s_2$ to both be steady, so in particular $s_1$ must be steady
at the input $i$, and $s_2$ must expose $o$; but, most importantly, $s_2$ must then be steady at the input
$\expose{S_1}(s_1)$ which $s_1$ exposes.

So, to find the set of
$\lens{\true}{\true}$-steady states of $\Sys{S}$, we must find a state $s_{1}$ of
$\Sys{S_1}$ which is steady for the input $\true$ and then a steady state $s_{2}$ of
$\Sys{S_2}$ whose input is what $s_{1}$ outputs and whose output is $\true$.
There are three pieces of data here: the steady state $s_{1}$ of $\Sys{S_1}$, the steady state $s_{2}$ of
$\Sys{S_2}$, and the intermediate value expose by the first state and input into
the second state. We can therefore describe the set of $\lens{\true}{\true}$-steady states of
$\Sys{S}$ like this:
\begin{align*}
  \Set{Steady}_{\Sys{S}}\lens{\true}{\true} &= \left\{ (m, s_1, s_2)
  \middle| \begin{aligned}
    s_1 &\in \Set{Steady}_{\Sys{S_1}}\lens{\true}{m},
    s_2 &\in \Set{Steady}_{\Sys{S_2}}\lens{m}{\true}
  \end{aligned}\right\} \\
  &= \sum_{m \in \Set{Colors}} \Set{Steady}_{\Sys{S_1}} \lens{\true}{m} \times \Set{Steady}_{\Sys{S_2}}\lens{m}{\true}.
\end{align*}

This formula looks very suspiciously like matrix multiplication! Indeed, if we
multiply the matrices of numbers of steady states from $\Sys{S_1}$ and
$\Sys{S_2}$, we get:
\[\kbordermatrix{
    &  &  &  \\
    \true & 0 & 1 & 0 \\
    \false & 2 & 0 & 0
}   
\kbordermatrix{
    & \true & \false \\
     & 2 & 0 \\
     & 1 & 0 \\
     & 0 & 1
}
= \kbordermatrix{
  & \true & \false \\
  \true & 1 & 0 \\
  \false & 4 & 0 
} 
\]
which is the matrix of how many steady states $\Sys{S}$ has! What's even more
suspicious is that our wiring diagram for $\Sys{S}$ looks a lot like the string
diagram we would use to describe the multiplication of matrices:
\[
\begin{tikzpicture}[oriented WD, bbx = .3cm, bby =.3cm, bb min width=.5cm, bb port length=2pt, bb port sep=1, every fit/.style={inner xsep=\bbx, inner ysep=\bby}
, baseline=(Outer.center)]
  \node[bb={1}{1}, fill=blue!10] (S1) {$\Sys{S_1}$};
  \node[bb={1}{1}, fill=blue!10, right= of S1] (S2) {$\Sys{S_2}$};

  \node[bb={1}{1}, fit={(S1) (S2)}] (Outer) {};

  \draw (Outer_in1) to (S1_in1);
  \draw (S1_out1) to (S2_in1);
  \draw (S2_out1) to (Outer_out1);
\end{tikzpicture} \quad\quad\quad\quad
\begin{tikzpicture}[oriented WD, bb small, bb port length=5pt, baseline=(f)]
	\node[bb={1}{1}, rounded corners=5pt, draw=dgreen] (f) {$\Set{Steady}_{\Sys{S_1}}$};
	\node[bb={1}{1}, rounded corners=5pt, draw=dgreen, right=3 of f] (g) {$\Set{Steady}_{\Sys{S_2}}$};
	\node[left=0 of f_in1] {$\Set{Bool}$};
	\node[right=0 of g_out1] {$\Set{Bool}$};
	\draw (f_out1) to node[above, font=\scriptsize] {$\Set{Colors}$} (g_in1);
\end{tikzpicture}
\]
This can't just be a coincidence. Luckily for our sanity, it isn't. In the
remainder of this section, we will show how various things one can do with
matrices --- multiply them, trace them, Kronecker product them --- can be done
for matrices of sets, and how if your wiring diagram looks like its telling you
to do that thing, then you can do that thing to the steady states of your internal
systems to get the steady states of the whole wired system

\paragraph{Matrices of sets}\label{sec.matrix_of_sets}

We'll be working with matrices of sets --- now and in the coming section ---
quite a bit, so we should really nail them down. Matrices of sets work a lot
like matrices of numbers, especially when the sets are finite; then they are
very nearly the same thing as matrices of whole numbers. But the matrix
arithmetic of infinite sets works just the same as with finite sets, so we'll do
everything in that generality.\footnote{This will help us later when we deal
  with behaviors that have more complicated charts. For example, even finite
  systems can have infinitely many different trajectories, so we really need the
  infinite sets.}

\begin{definition}\label{def.matrix_of_sets}
  Let $A$ and $B$ be two sets. $B \times A$ \emph{matrix of sets} is a dependent
  set $M : B \times A \to \smset$. For $a \in A$ and $b \in B$, we write
  $M_{ba}$ or $M_{(b, a)}$ for set indexed by $a$ and $b$, and call this the
  $(b,a)$-entry of the matrix $M$.


  We draw of matrix of sets with the following string diagram:
  \[
\begin{tikzpicture}[oriented WD, bb small, bb port length=5pt, baseline=(f)]
	\node[bb={1}{1}, rounded corners=5pt, draw=dgreen] (f) {$M$};
	\node[left=0 of f_in1] {$A$};
  \node[right=0 of f_out1] {$B$};
\end{tikzpicture}
  \]
\end{definition}
\begin{remark}
  We can see a dependent set $X_{-} : A \to \smset$ through the matrix of sets
  point of view as a \emph{vector of sets}. This is because $X_{-}$ is
  equivalently given by $X_{-} : A \times \ord{1} \to \smset$, which we see is a
  $A \times \ord{1}$ matrix of sets. A $n \times 1$ matrix is equivalently a
  column vector.
\end{remark}

Now we'll go through and define the basic operations of matrix arithmetic:
mutliplication, Kronecker product (also known as the tensor product), and
partial trace.

\begin{definition}\label{def.matrix_of_sets_multiplication}
  Given an $B \times A$ matrix of sets $M$ and a  $C \times B$ matrix of sets
  $N$, their \emph{product} $NM$ (or $M \times_B N$ for emphasis) is the $C
  \times A$ matrix of sets with entries
  $$NM_{ca} = \sum_{b \in B}  N_{cb}\times M_{ba}.$$

  We draw the multiplication of matrices of sets with the following string
  diagram:
  \[
\begin{tikzpicture}[oriented WD, bb small, bb port length=5pt, baseline=(f)]
	\node[bb={1}{1}, rounded corners=5pt, draw=dgreen] (f) {$M$};
	\node[bb={1}{1}, rounded corners=5pt, draw=dgreen, right=1.5 of f] (g) {$N$};
	\node[left=0 of f_in1] {$A$};
	\node[right=0 of g_out1] {$C$};
	\draw (f_out1) to node[above, font=\scriptsize] {$B$} (g_in1);
\end{tikzpicture}
  \]
   
  The identity matrix $I_A$ is an $A \times A$ matrix with entries
  $$I_{aa'} = \begin{cases} \ord{1} &\mbox{if $a = a'$} \\ \emptyset &\mbox{if
      $a \neq a'$} \end{cases}.$$

  We draw the identity matrix as a string with no beads on it.
  \[
\begin{tikzpicture}[oriented WD, bb small, bb port length=5pt, baseline=(Left)]
  \node (Left) (Left){};
  \node[right = 3 of Left](Right) {};
  \draw (Left.center) -- (Right.center);
  \node[left=0 of Left] {$A$};
  \node[right=0 of Right] {$A$};
\end{tikzpicture}
  \]
  
\end{definition}

\begin{exercise}\label{ex.matrix_of_sets_mult_laws}
  Multiplication of matrices of sets satisfies the usual properties of
  associativity and unity, but only up to isomorphism. Let $M$ be a $B \times A$
  matrix, $N$ a $C \times B$ matrix, and $L$ a $D \times C$ of sets. Show that
  \begin{enumerate}
   \item  For all $a \in A$ and $d \in D$, $((LN)M)_{da} \cong (L(NM))_{da}$.
   \item For all $a \in A$ and $b \in B$, $(MI_A)_{ba} \cong M_{ba} \cong (I_BM)_{ba}$.
  \end{enumerate}
\end{exercise}

\begin{remark}
  The isomorphisms you defined in \cref{ex.matrix_of_sets_mult_laws} are
  \emph{coherent}, much in the way the associativity and unity isomorphisms of a
  monoidal category are. Together, this means that there is a \emph{bicategory}
  of sets and matrices of sets between them. 
\end{remark}

\begin{definition}\label{def.matrix_of_sets_tensor}
  Let $M$ be a $B \times A$ matrix and $N$ a $C \times D$ matrix of sets. Their
  \emph{Kronecker product} or \emph{tensor product} $M \otimes N$ is a $(B
  \times C) \times (A \times D)$ matrix of sets with entries:
  $$(M \otimes N)_{(b, c)(a, d)} = M_{ba} \times N_{cd}.$$

  We draw the tensor product $M \otimes M$ of matrices as:
  \[
\begin{tikzpicture}[oriented WD, bb small, bb port length=5pt, baseline=(f)]
	\node[bb={1}{1}, rounded corners=5pt, draw=dgreen] (f) {$M$};
	\node[bb={1}{1}, rounded corners=5pt, draw=dgreen, below= of f] (g) {$N$};
	\node[left=0 of f_in1] {$A$};
	\node[right=0 of f_out1] {$B$};
	\node[right=0 of g_out1] {$D$};
	\node[left=0 of g_in1] {$C$};
\end{tikzpicture}
  \]
\end{definition}

Finally, we need to define the partial trace of a matrix of sets.
\begin{definition}
  Suppose that $M$ is a $(A \times C) \times (A \times B)$ matrix of sets. Its
  \emph{partial trace} $\fun{tr}_{A} M$ is a $C \times B$ matrix of sets with
  entries:
  $$(\fun{tr}_{A})M_{cb} = \sum_{a \in A} M_{(a,c)(a,b)}.$$

    We draw the partial trace of a matrix of sets as:
\[
\begin{tikzpicture}[oriented WD, bb small, bb port length=5pt, baseline=(M)]
	\node[bb={2}{2}, rounded corners=5pt, draw=dgreen] (M) {$M$};
	\node[left=1.5 of M_in2] (B) {$B$};
	\node[right=1.5 of M_out2] (C) {$C$};
  \draw let \p1=(M.north east), \p2=(M.north west), \n1={\y2+\bby}, \n2=\bbportlen in
          (M_out1) to[in=0] (\x1+\n2,\n1) -- node[above, font=\scriptsize] {$A$} (\x2-\n2,\n1) to[out=180] (M_in1);
  \draw (B) to (M_in2);
  \draw (M_out2) to (C);
\end{tikzpicture}
\]
\end{definition}

\begin{exercise}\label{ex.matrix_of_sets_sanity_check}
Here's an important sanity check we should do about our string diagrams for
matrices of sets. The following two diagrams should describe the same matrix,
even though they describe it in different ways:
    \[
\begin{tikzpicture}[oriented WD, bb small, bb port length=5pt, baseline=(f)]
	\node[bb={1}{1}, rounded corners=5pt, draw=dgreen] (f) {$M$};
	\node[bb={1}{1}, rounded corners=5pt, draw=dgreen, right=1.5 of f] (g) {$N$};
	\node[left=0 of f_in1] {$A$};
	\node[right=0 of g_out1] {$C$};
	\draw (f_out1) to node[above, font=\scriptsize] {$B$} (g_in1);
\end{tikzpicture}
\quad\quad\quad\quad
\begin{tikzpicture}[oriented WD, bb small, bb port length=5pt, baseline=(Q)]
  \node[bb={1}{1}, rounded corners=5pt, draw=dgreen] (M) {$M$};
  \node[bb={1}{1}, rounded corners=5pt, draw=dgreen, below= of M] (N) {$N$};
  \node[bb={0}{0}, rounded corners=5pt, draw=dgreen, dashed, fit={(N) (M)}] (Q) {};

  \node[left = 3 of Q.center] (Left) {$A$};
  \node[right = 3 of Q.center] (Right) {$C$};

  \draw let \p1=(Q.north east), \p2=(Q.south west), \n1={\y2-\bby}, \n2=\bbportlen in    (M_out1-|Q.east) to[in=0] (\x1 +\n2, \n1) -- node[below, font=\scriptsize] {$B$} (\x2-\n2, \n1) to[out=180] (N_in1-|Q.west);
  \draw (Left) to[out=0, in=180] (M_in1-|Q.west);
  \draw (N_out1-|Q.east) to[out=0, in=180] (Right);
\end{tikzpicture}
    \]
The diagram on the left says ``multiply $M$ and $N$'', while the diagram on the
right says ``tensor $M$ and $N$, and then partially trace them.''. Show that
these two diagrams do describe the same matrix:
$$NM \cong \fun{tr}_{B}(M \otimes N).$$
Compare this to \cref{ex.ClockWithDisplay}, where we say that wiring an input of
a system to an output of another can be seen as first taking their parallel
product, and then forming a loop.
\end{exercise}

\paragraph{Steady states and matrix arithmetic}

For the remainder of this section, we will show that we can calculate the steady
state matrix of a composite system in terms of its component system in a
very simple way:
\begin{itemize}
  \item First, take the steady state matrices of the component systems.
  \item Then consider the wiring diagram as a string diagram for multiplying,
tensoring, and tracing matrices.
  \item Finally, finish by doing all those operations to the matrix.
\end{itemize}

In \cref{sec.representables}, we will see that this method --- or something a
lot like it --- works calculating the behaviors of a composite system out of the
behaviors of its components, as long as the representative of that behavior
exposes its entire state. That result will be nicely packaged in a beautiful
categorical way: we'll make an \emph{doubly indexed functor}.

But for now, let's just show that tensoring and partially tracing steady state
matrices correponds to taking the parallel product and wiring an input to an
output, respectively, of systems.

\begin{proposition}\label{prop.steady_state_matrix_parallel_tensor}
  Let $\Sys{S_1}$ and $\Sys{S_2}$ be systems. Then the steady state matrix of the
  parallel product $\Sys{S_1 \otimes S_2}$ is the tensor of their steady state
  matrices:
  $$\Set{Steady}_{\Sys{S_1 \otimes S_2}} \cong \Set{Steady}_{\Sys{S_1}} \otimes \Set{Steady}_{\Sys{S_2}}.$$
\end{proposition}
\begin{proof}
  First, we note that these are both $(\Out{S_1} \times \Out{S_2}) \times
  (\In{S_1} \times \In{S_2})$-matrices of sets. Now, on a chart $\lens{(i_1,
    i_2)}{(o_1, o_2)}$, a steady state in $\Sys{S_1} \otimes \Sys{S_2}$ will be
  a pair $(s_1, s_2) \in \State{S_1} \times \State{S_2}$ such that
  $\update{S_j}(s_j, i_j) = s_j$ and $\expose{S_j}(s_j) = o_j$ for $j = 1,\, 2$.
  In other words, its just a pair of steady states, one in $\Sys{S_1}$ and one
  in $\Sys{S_2}$. This is precisely the $\lens{(i_1, i_2)}{(o_1, o_2) }$-entry
  of the right hand side above. 
\end{proof}


\begin{remark}
  \cref{prop.steady_state_matrix_parallel_tensor} is our motiviation for using
  the symbol ``$\otimes$'' for the parallel product of systems.
\end{remark}

\begin{proposition}\label{prop.steady_state_matrix_trace}
Let $\Sys{S}$ be a system with $\In{S} = A \times B$ and $\Out{S} = A \times C$.
Let $\Sys{S'}$ be the system formed by wiring the $A$ output into the $A$ input
of $\Sys{S}$:
\[\Sys{S'} \coloneqq
\begin{tikzpicture}[oriented WD, every fit/.style={inner xsep=\bbx, inner ysep=\bby}, bbx = .3cm, bby =.3cm, bb min width=.5cm, bb port length=2pt, bb port sep=1, baseline=(S'.center)]
	\node[bb={2}{2}, fill=blue!10] (S) {$\Sys{S}$};

  \node[bb={0}{0}, fit={($(S.north east) + (1,1)$) ($(S.south west) - (1,0)$)}] (S') {};
  
  \draw (S_out2) to (S_out2-|S'.east);
  \draw (S_in2-|S'.west) to (S_in2);

  \draw let \p1=(S.north east), \p2=(S.north west), \n1={\y2+\bby}, \n2=\bbportlen in    (S_out1) to[in=0] (\x1 +\n2, \n1) -- (\x2-\n2, \n1) to[out=180] (S_in1);
\end{tikzpicture}
\]
Then the steady state matrix of $\Sys{S'}$ is given by partially tracing out $A$
in the steady state matrix of $\Sys{S}$:
\[
  \Set{Steady}_{\Sys{S'}} = 
\begin{tikzpicture}[oriented WD, bb small, bb port length=5pt, baseline=(M)]
	\node[bb={2}{2}, rounded corners=5pt, draw=dgreen] (M) {$\Set{Steady}_{\Sys{S}}$};
	\node[left=1.5 of M_in2] (B) {};
	\node[right=1.5 of M_out2] (C) {};
  \draw let \p1=(M.north east), \p2=(M.north west), \n1={\y2+\bby}, \n2=\bbportlen in
          (M_out1) to[in=0] (\x1+\n2,\n1) -- node[above, font=\scriptsize] {$A$} (\x2-\n2,\n1) to[out=180] (M_in1);
  \draw (B) to (M_in2);
  \draw (M_out2) to (C);
\end{tikzpicture} = \fun{tr}_{A}\left(\Set{Steady}_{\Sys{S}}\right)
\]
\end{proposition}
\begin{proof}
  Let's first see what a steady state of $\Sys{S'}$ would be. Since $\Sys{S'}$
  is just a rewiring of $\Sys{S}$, it has the same states; so, a steady state $s$ of
  $\Sys{S'}$ is in particular a state of $\Sys{S}$. Now,
  $$\update{S'}(s,b) = \update{S}(s, (\pi_1\expose{S}(s), b))$$
  by definition, so if $\update{S'}(s, b) = s$, then $\update{S}(s, (\pi_1\expose{S}(s),
  b)) = s$. If also $\expose{S'}(s) = c$ (so that $s$ is a
  $\lens{b}{c}$-steady state of $\Sys{S'}$), then $\pi_2\expose{S}(s) =
  \expose{S'}(s) = c$ as well. In total then, starting with a
  $\lens{b}{c}$-steady state $s$ of $\Sys{S'}$, we get a
  $\lens{(\pi_1\expose{S}(s), b)}{(\pi_1\expose{S}(s), c)}$-steady state of
  $\Sys{S}$.  That is, we have a function
  $$s \mapsto (\pi_1 \expose{S}(s), s) : \Set{Steady}_{\Sys{S'}}\lens{b}{c} \to
  (\fun{tr}_{A} \Set{Steady}_{\Sys{S}}) \lens{b}{c}.$$

  It remains to show that this function is a bijection. So, suppose we have a
  pair $(a, s) \in \fun{tr}_A \Set{Steady}_{\Sys{S}}\lens{b}{c}$ of an $a \in A$ and a
  $\lens{(a, b)}{(a, c)}$ steady state of $\Sys{S}$. Then
  \begin{align*}
    \update{S'}(s, b) &= \update{S}(s, (\pi_1\expose{S}(s), b)) \\
                      &= \update{S}(s, (a, b)) &\mbox{since $\expose{S}(s) = (a, c)$.}\\
                      &= s &\mbox{since $s$ is a $\lens{(a, b)}{(a, c)}$-steady state.}\\
    \expose{S'}(s) &= \pi_2\expose{S}(s) = c.
  \end{align*}
  This shows that $s$ is also a $\lens{b}{c}$ steady state of $\Sys{S'}$, giving
  us a function
  $(a, s) \mapsto s : (\fun{tr}_A \Set{Steady}_{\Sys{S}}) \to \Set{Steady}_{\Sys{S'}}.$
  These two functions are plainly inverse.
\end{proof}

We can summarize \cref{prop.steady_state_matrix_trace} in the following
commutative diagram:
\begin{equation}\label{eqn.steady_state_matrix_compose}
\begin{tikzpicture}
\node[draw] (Topleft) {
\begin{tikzpicture}[oriented WD, every fit/.style={inner xsep=\bbx, inner ysep=\bby}, bbx = .3cm, bby =.3cm, bb min width=.5cm, bb port length=2pt, bb port sep=1, baseline=(S)]
	\node[bb={2}{2}, fill=blue!10] (S) {$\Sys{S}$};
\end{tikzpicture}
\
};


\node[draw, below = 4 of Topleft] (Botleft) {
\begin{tikzpicture}[oriented WD, every fit/.style={inner xsep=\bbx, inner ysep=\bby}, bbx = .3cm, bby =.3cm, bb min width=.5cm, bb port length=2pt, bb port sep=1, baseline=(S'.center)]
	\node[bb={2}{2}, fill=blue!10] (S) {$\Sys{S}$};

  \node[bb={0}{0}, fit={($(S.north east) + (1,1)$) ($(S.south west) - (1,0)$)}] (S') {};
  
  \draw (S_out2) to (S_out2-|S'.east);
  \draw (S_in2-|S'.west) to (S_in2);

  \draw let \p1=(S.north east), \p2=(S.north west), \n1={\y2+\bby}, \n2=\bbportlen in    (S_out1) to[in=0] (\x1 +\n2, \n1) -- (\x2-\n2, \n1) to[out=180] (S_in1);
\end{tikzpicture}
};



\node[draw, right = 4 of Botleft]  (Botright) {
\begin{tikzpicture}[oriented WD, bb small, bb port length=5pt, baseline=(M)]
	\node[bb={2}{2}, rounded corners=5pt, draw=dgreen] (M) {$\Set{Steady}_{\Sys{S}}$};
	\node[left=1.5 of M_in2] (B) {};
	\node[right=1.5 of M_out2] (C) {};
  \draw let \p1=(M.north east), \p2=(M.north west), \n1={\y2+\bby}, \n2=\bbportlen in
          (M_out1) to[in=0] (\x1+\n2,\n1) -- (\x2-\n2,\n1) to[out=180] (M_in1);
  \draw (B) to (M_in2);
  \draw (M_out2) to (C);
\end{tikzpicture}
};

\node[draw] at (Botright|-Topleft)(Topright) {
\begin{tikzpicture}[oriented WD, bb small, bb port length=5pt, baseline=(f)]
	\node[bb={2}{2}, rounded corners=5pt, draw=dgreen] (f) {$\Set{Steady}_{\Sys{S}}$};
\end{tikzpicture}
};

\draw[->, shorten <= 5pt, shorten >= 5pt] (Topleft) to node[above] {$\Set{Steady}$} (Topright);
\draw[->, shorten <= 5pt, shorten >= 5pt] (Botleft) to node[below] {$\Set{Steady}$} (Botright);
\draw[->, shorten <= 5pt, shorten >= 5pt] (Topleft) to coordinate[left] (Leftlabel) (Botleft);
\draw[->, shorten <= 5pt, shorten >= 5pt] (Topright) to coordinate[right] (Rightlabel) (Botright);

\node[left = 0 of Leftlabel] {
\begin{tikzpicture}[oriented WD, every fit/.style={inner xsep=\bbx, inner ysep=\bby}, bbx = .3cm, bby =.3cm, bb min width=.5cm, bb port length=2pt, bb port sep=1, baseline=(S'.center)]
	\node[bb={2}{2}, fill=blue!10, dashed] (S) {};

  \node[bb={0}{0}, fit={($(S.north east) + (1,1)$) ($(S.south west) - (1,0)$)}] (S') {};
  
  \draw (S_out2) to (S_out2-|S'.east);
  \draw (S_in2-|S'.west) to (S_in2);

  \draw let \p1=(S.north east), \p2=(S.north west), \n1={\y2+\bby}, \n2=\bbportlen in    (S_out1) to[in=0] (\x1 +\n2, \n1) -- (\x2-\n2, \n1) to[out=180] (S_in1);
\end{tikzpicture}
};
\node[right= 0 of Rightlabel] {
\begin{tikzpicture}[oriented WD, bb small, bb port length=5pt, baseline=(M)]
	\node[bb={2}{2}, rounded corners=5pt, draw=dgreen, dashed] (M) {$\phantom{\Set{Steady}_{\Sys{S}}}$};
	\node[left=1.5 of M_in2] (B) {};
	\node[right=1.5 of M_out2] (C) {};
  \draw let \p1=(M.north east), \p2=(M.north west), \n1={\y2+\bby}, \n2=\bbportlen in
          (M_out1) to[in=0] (\x1+\n2,\n1) -- (\x2-\n2,\n1) to[out=180] (M_in1);
  \draw (B) to (M_in2);
  \draw (M_out2) to (C);
\end{tikzpicture}
};
\end{tikzpicture}
\end{equation}

The horizontal maps take the steady states of a system, while the vertical map
on the left wires together the system with that wiring diagram, and the vertical
map on the right applies that transformation of the matrix. In the next section,
we will see how this square can be interepreted as a naturality condition in a
\emph{doubly indexed functor}.

One thing to notice here is that taking the partial trace (the right vertical
arrow in the diagram) is itself given by multiplying by a certain matrix.
\begin{proposition}\label{prop.trace_multiplying_by_matrix}
  Let $M$ be a $(A \times C) \times (A \times B)$ matrix of sets. Let
  $\Set{Tr}^A$ be the $\big(C \times B \big) \times \big((A \times C) \times (A
  \times B)\big)$ matrix of sets with entries:
  \[
    \Set{Tr}^A{A}_{(c, b)((a,c'),(a', b'))} \coloneqq \begin{cases} 
      \ord{1} &\mbox{if $a = a'$, $b = b'$, and $c = c'$.} \\
      \emptyset &\mbox{otherwise.}
    \end{cases} 
\]
  Then, considering $M$ as a $\big((A \times C) \times (A \times B)\big) \times
  \ord{1}$ matrix of sets, taking its trace is given by multiplying by $\Set{Tr}^A$:
$$\fun{tr}_{A}M \cong \Set{Tr}^A M$$
\end{proposition}
\begin{proof}
  Let's calculate that matrix product on the right.
  \begin{align*}
    (\Set{Tr}^A M)_{(c, b)} &= \sum_{((a, c'), (a', b')) \in (A \times C) \times (A \times B)} \Set{Tr}^A_{(c,b)((a, c'),(a', b'))} \times M_{(a,c')(a',b')} \\
  \end{align*}
  Now, since $\Set{Tr}^A_{(c,b)((a,c'),(a',b'))}$ is a one element set (if $a =
  a'$, $c = c'$, and $b = b'$) and is empty otherwise, the inner expression has
  the elements of $M_{(a,c')(a', b')}$ if and only if $a = a'$, $b = b'$, and $c
  = c'$ and is otherwise empty. So, we conclude that
  \[
\sum_{((a, c'), (a', b')) \in (A \times C) \times (A \times B)}
\Set{Tr}^A_{(c,b)((a, c'),(a', b'))} \times M_{(a,c')(a',b')} \cong M_{(a, c)(a,
  b)}.\qedhere
\]
\end{proof}








%---- Section ----%
\section{The big theorem: representable doubly indexed functors}

We have now introduced all the characters in our play: the double categories of
arenas and matrices, and doubly indexed categories of systems and vectors. In
this section, we will put the plot in motion. 

In \cref{sec.steady_states_matrix_arithmetic}, we saw that the steady states of
dynamical systems with interface $\lens{I}{O}$ compose like an $I \times O$
matrix. We proved a few propositions to this effect, namely
\cref{prop.steady_state_matrix_parallel_tensor} and
\cref{prop.steady_state_matrix_trace}, but we didn't precisely mark out the
scope of these results, or describe the full range of laws that are satisfied.

In this section, we will generalize the results of that section to \emph{all
  behaviors} of systems, not just steady states. We will precisely state all the
ways that behaviors can be composed by systems, and we will give a condition on
the kinds of behaviors for which we can calculate the behavior of a wired
together system entirely from the behavior of its component systems. All of this will be organized into a \emph{doubly indexed functor}
$\Fun{Behave}_{\Sys{T}} : \Cat{Sys} \to \Cat{Vec}$
which will send a system $\Sys{S}$ to its set of
$\Sys{T}$-shaped behaviors. 

In fact, our definition of $\Fun{Behave}_{\Sys{T}}$ will be entirely abstract;
it will work for almost any doubly indexed category $\cat{A} : \cat{D} \to \Cat{Cat}$ (there is a small condition
on the indexing double category $\cat{D}$). $\Fun{Behave}_{\Sys{T}}$ will be a
\emph{representable} doubly indexed category. Before going on to construct
representable doubly indexed categories, let's take a minute to refresh
ourselves on what representable functors are for categories. The essential idea
is the same.

If $\cat{C}$ is a category and $T$ an object of $\cat{C}$, then we can see maps $f : T
\to X$ as ``figures of shape $T$ in $X$''. It is often the case that we have
some other way of talking about figures of shape $T$ in $X$ in terms that don't
mention $T$ --- in this case we say that $T$ \emph{represents} figures of shape
$T$. This phenomenon is very widespread,
so let's give a number of examples:
\begin{itemize}
  \item Suppose that $\cat{C}$ is the category of sets, and $T = \ord{1}$ is a one
    element set. Then a map $f : T \to X$ uniquely picks out an element of $X$.
    We see that $T$ has the shape of a single element, and a map from $T$ to $X$
    is a thing in $X$ whose shape is an element; that is, an element of $X$. We
    can say that $\ord{1}$ represents elements.
   \item Suppose that $\cat{C}$ is the category of sets, but now that $T = \ord{2}$
     is a two-element set. A two-element set is an abstract pair of elements,
     and a map $f : T \to X$ now picks out a pair of elements in $X$. We can say
     that $\ord{2}$ represents pairs.
   \item Suppose that $\cat{C}$ is the category of simple, undirected graphs --- that
     is, sets $X$ equipped with an irreflexive relation $E_X \subseteq X \times
     X$ telling us which two elements are connected by an edge. The maps of this
     category need to preserve edges. If $T$ is the graph consisting of a single
     edge (formally, $T = \ord{2}$ with $(0, 1) \in E_T$ being the only edge),
     then a map $f : T \to X$ must pick out a pair of points in $X$ with an edge
     between them. In other words, maps $T \to X$ are edges in $X$. So we may
     say that $T$ represents edges.
   \item Suppose that $\cat{C}$ is the category of rings, and let $T = \zz[x, y]$ be
     the ring of polynomials in two variables. A ring homomoprhism $f : T \to X$
     can send $x$ to any element $f(x)$ and similarly $y$ to any element $f(y)$;
     once it's done that, the value of $f$ on any polynomial in $x$ and $y$ must
     be given by
     $$f\left( \sum a_{ij}x^iy^j \right) = \sum a_{ij}f(x)^if(y)^j.$$
     since $f$ is presumed to be a ring homomorphism. Actually, there is one
     constraint on $f(x)$ and $f(y)$ for this to work; since $xy = yx$ as
     polynomials, we must have $f(x)f(y) = f(y)f(x)$. Therefore, we see that
     $\zz[x, y]$ represents pairs of elements which commute in the category of rings.
     \item As we saw in \cref{chapter.3}, all sorts of behaviors of systems ---
       trajectories, periodic orbits, steady states, etc --- are represented
       by simple systems in the category of systems and behaviors between them. 
\end{itemize}

We could continue endlessly. The idea of representability is fundamental in
category theory. Let's make it a little more explicit exactly what it means for
$T$ to represent something.

If $T$ is an object of $\cat{C}$, then for any object $X$ of $\cat{C}$ we get a
\emph{set} $\cat{C}(T, X)$ of all maps from $T$ to $X$ in $\cat{C}$. If $g : X
\to Y$ is a map in $\cat{C}$, then for any $f : T \to X$ we get a map $f \then g : T
\to Y$; in other words, for $g : X \to Y$ we get a map $\cat{C}(T, X) \xto{-
  \then g} \cat{C}(T, Y)$ given by post-composing with $g$. This gives us a
\emph{functor} $\cat{C}(T, -) : \cat{C} \to \smset$. This is a representable
functor.

The idea of this section is to use the fact that behaviors are represented by
simple systems to prove a compositionality result. This compositionality result
is packaged up into a doubly indexed functor, and we will construct it as a representable doubly
indexed functor. Instead of going from a category to the category of sets as
representable functors do, our representable doubly indexed functors will go
from a doubly indexed category (satisfying a little condition) to the doubly
indexed category $\Cat{Vec}$ of vectors of sets.


\subsection{Turning lenses into matrices: Representable double Functors}

In \cref{sec.steady_states_matrix_arithmetic}, we saw how we could re-interpret
a wiring diagram as a schematic for multiplying, tensoring, and tracing
matrices. At the very end, in \cref{prop.trace_multiplying_by_matrix}, we saw
that we can take the trace $\fun{tr}_A M$ of a $(A \times C) \times (A \times B)$-matrix $M$ by
considering it as a $(A \times C) \times (B \times C)$ length vector and then
multiplying it by a big but very sparse $(C \times B) \times ((A \times C) \times (B \times
C))$-matrix $\Fun{Tr}^A$. Taking the trace of a matrix corresponded to the
wiring diagram
\[
\begin{tikzpicture}[oriented WD, every fit/.style={inner xsep=\bbx, inner ysep=\bby}, bbx = .3cm, bby =.3cm, bb min width=.5cm, bb port length=2pt, bb port sep=1, baseline=(S'.center)]
	\node[bb={2}{2}, fill=blue!10, dashed] (S) {};

  \node[bb={0}{0}, fit={($(S.north east) + (1,1)$) ($(S.south west) - (1,0)$)}] (S') {};
  
  \draw (S_out2) to (S_out2-|S'.east);
  \draw (S_in2-|S'.west) to (S_in2);

  \draw let \p1=(S.north east), \p2=(S.north west), \n1={\y2+\bby}, \n2=\bbportlen in    (S_out1) to[in=0] (\x1 +\n2, \n1) -- (\x2-\n2, \n1) to[out=180] (S_in1);
\end{tikzpicture}
\]
In this section, we will see a general formula for taking an arbitrary lens and
turning it into a matrix. Mutliplying by the matrix will then correspond to
wiring according to that lens.

This process of turning a lens into a matrix will give us a functor $\Cat{Lens}
\to \Cat{Matrix}$ from the category of lenses to the category of matrices of
sets. We'll start by exploring this functor in the deterministic systems theory; then
we will abstract and find that the same argument works in any systems theory.

The resulting matrices will have entries that are either $\ord{1}$ or
$\emptyset$; we can think of this as telling us whether ($\ord{1}$) or not ($\emptyset$) the two charts
are to be wired together. As we saw in
\cref{ex.understanding_squares_in_double_cat_of_arenas}, we can see a square in the double
category of arenas as telling us how a chart can be wired together along
a lens into another chart. Therefore, we will take the entries of our matrices
to be the sets of appropriate squares in arena --- but there is either a single
square (if the appropriate equations hold) or no square (if they don't), so we
will end up with a matrix whose entries either have a single element or are empty.


\begin{proposition}\label{prop.lens_to_matrix_functor_discrete}
  For any arena in the deterministic systems theory $\lens{I}{O}$, there is a functor
$$\Cat{Chart}_{\determ}\left( \littlelens{I}{O},\, - \right) : \Cat{Lens}_{\determ} \to \Cat{Matrix}$$
from the category of lenses to the category of matrices of sets which sends an
arena $\lens{A^-}{A^+}$ to the set $\Cat{Chart}_{\determ}\left( \lens{I}{O},
  \lens{A^-}{A^+} \right)$ of charts from $\lens{I}{O}$ to $\lens{A^-}{A^+}$,
and which sends a lens $\lens{w^{\sharp}}{w} : \lens{A^-}{A^+} \fromto
\lens{B^-}{B^+}$ to the $\Cat{Chart}_{\determ}\left( \lens{I}{O}, \lens{B^-}{B^+} \right)
\times \Cat{Chart}_{\determ}\left( \lens{I}{O}, \lens{A^-}{A} \right)$ matrix of sets
\begin{align*}
 \Cat{Chart}_{\determ}\left( \littlelens{I}{O}, \littlelens{w^{\sharp}}{w} \right) &: \Cat{Chart}_{\determ}\left( \littlelens{I}{O}, \littlelens{B^-}{B^+} \right)
\times \Cat{Chart}_{\determ}\left( \littlelens{I}{O}, \littlelens{A^-}{A} \right) \to \smset \\
\left( \littlelens{f_{\flat}}{f}, \littlelens{g_{\flat}}{g} \right) &\mapsto \left\{ \mbox{ The set of squares }
      \begin{tikzcd}[ampersand replacement = \&]
        \lens{I}{O} \ar[r, shift left, "\lens{f_{\flat}}{f}"] \ar[r, shift
        right] \ar[d, shift right, equals] \ar[d, shift left,
        leftarrow, equals] \& \lens{A^-}{A^+} \ar[d, shift left, leftarrow,
        "\lens{w^{\sharp}}{w}"] \ar[d, shift right]\\
        \lens{I}{O} \ar[r, shift right, "\lens{g^{\sharp}}{g}"'] \ar[r,
        shift left] \& \lens{B^-}{B^+}
      \end{tikzcd}  \mbox{ in $\Cat{Arena}_{\determ}$}   \right\} \\
&=\begin{cases} \ord{1} &\mbox{ if \(\begin{cases} g(o) = w(f(o)) &\mbox{ for all $o \in O$,}\\ f_{\flat}(i, o) = w^{\sharp}(f(o), g_{\flat}(i, o)) &\mbox{for all $i \in I$ and $o \in O$.}\end{cases}\)} \\ \emptyset &\mbox{otherwise} \end{cases}
\end{align*}
\end{proposition}
\begin{proof}
By vertical composition of squares,
\[
  \begin{tikzcd}
    \lens{I}{O} \ar[r, shift left, "\lens{f_{\flat}}{f}"] \ar[r, shift right] \ar[d, shift right,
    equals] \ar[d, shift left, equals] &
    \lens{A^-}{A^+} \ar[d, shift left, leftarrow,
    "\lens{w^{\sharp}}{w}"] \ar[d, shift right]\\
    \lens{I}{O} \ar[d, shift right, equals] \ar[d, shift left,
        equals] \ar[r, shift right, "\lens{g_{\flat}}{g}"']
    \ar[r, shift left] & \lens{B^-}{B^+} \ar[d, shift left, leftarrow,
        "\lens{v^{\sharp}}{v}"] \ar[d, shift right]\\
    \lens{I}{O} \ar[r, shift right, "\lens{h_{\flat}}{h}"']
    \ar[r, shift left] & \lens{I'}{O'} 
  \end{tikzcd} \xequals{\quad}
  \begin{tikzcd}
    \lens{I}{O} \ar[r, shift left, "\lens{f_{\flat}}{f}"] \ar[r, shift right] \ar[d, shift right,
    equals] \ar[d, shift left, equals] &
    \lens{A^-}{A^+} \ar[d, shift left, leftarrow,
    "\lens{w^{\sharp}}{w} \then \lens{v^{\sharp}}{v}"] \ar[d, shift right]\\
    \lens{I}{O} \ar[r, shift right, "\lens{h_{\flat}}{h}"']
    \ar[r, shift left] & \lens{I}{O'}
  \end{tikzcd}
\]
there is always a map from the composite of two of these matrices to the matrix
described by the composite. It is not, however, obvious that this map is a
bijection --- which is what we need to prove functoriality.

Suppose we have a square as on the left hand side; let's see that we can factor
it into two squares as on the right hand side. We need to construct the middle
chart $\lens{g_{\flat}}{g} : \lens{I}{O} \tto \lens{B^-}{B^+}$ from
$\lens{f_{\flat}}{f}$ and $\lens{h_{\flat}}{h}$. For the bottom of top square to commute,
we see that $g$ must equal $w \circ f$, so we can define $g \coloneqq w \circ
f$. On the other hand, for the top of the bottom square to commute, we must have that
$g_{\flat}(i, o) = v^{\sharp}(g(o), h_{\flat}(i, o))$; again, we can take this
as a definition. It remains to show that the other half of each square commutes.
For the top of the top square to commute means that
$$f_{\flat}(i, o) = w^{\sharp}(f(o), g_{\flat}(i, o))$$
which we can see holds by
\begin{align*}
  w^{\sharp}(f(o), g_{\flat}(i, o)) &= w^{\sharp}(f(o), v^{\sharp}(g(o), h_{\flat}(i, o))) \\
                                    &= w^{\sharp}(f(o), v^{\sharp}(wf(o), h_{\flat}(i, o))) \\
                                    &= f_{\flat}(i, o) \\
                                    &\phantom{=}\quad\mbox{by the commutativity of the square on the right.}
\end{align*}

On the other hand, to show that the bottom of the bottoms square commutes, we
need that $h =  v \circ g$. But by hypothesis, $h = v \circ w \circ f$, and we
defined $g = w \circ f$.
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Decided to remove this proof, but keeping the text for later, in case.
\iffalse
\begin{proof}
  To prove that this is a functor, it will help to reinterpret the matrix above
  in terms of diagrams in the category of charts. We can crack the lens
  $\lens{w^{\sharp}}{w} : \lens{A^-}{A^+} \fromto \lens{B^-}{B^+}$ into two
  charts: 
\begin{itemize}
  \item $\lens{w^{\sharp}}{\id} : \lens{B^-}{A^+} \tto \lens{A^-}{A+}$, and
  \item $\lens{\pi_2}{w} : \lens{B^-}{A^+} \tto \lens{B^-}{B^+}$.
\end{itemize}
Note that we've cracked the lens into two \emph{charts}. Now, we can interpret
the matrix $\Cat{Chart}\left( \littlelens{I}{O}, \littlelens{w^{\sharp}}{w}
\right)$ as sending charts $\lens{f_{\flat}}{f} : \lens{I}{O} \tto
\lens{A^-}{A^+}$ and $\lens{g_{\flat}}{g} : \lens{I}{O} \tto \lens{B^-}{B^+}$ to
the set of charts $\lens{h_{\flat}}{h} : \lens{I}{O} \tto \lens{B^-}{A^+}$ so
that the following diagram in $\Cat{Arena}$ commutes:
\[
\begin{tikzcd}
  \lens{I}{O} \ar[d, equals, shift left]\ar[d, equals, shift right] \ar[r, shift
  left, "\littlelens{f_{\flat}}{f}"]\ar[r, shift right]& \lens{A^-}{A^+} \ar[d,
  shift left, leftarrow, "\lens{w^{\sharp}}{\id}"] \ar[d, leftarrow, shift right] \\
  \lens{I}{O} \ar[d, equals, shift left]\ar[d, equals, shift right] \ar[r,
  dashed, shift left, "\littlelens{h_{\flat}}{h}"]\ar[r, dashed, shift right]& \lens{B^-}{A^+} \ar[d,
  shift left, "\lens{\pi_2}{w}"] \ar[d, shift right] \\
  \lens{I}{O} \ar[r, shift
  left]\ar[r, shift right, "\littlelens{g_{\flat}}{g}"']& \lens{B^-}{B^+}
\end{tikzcd}
\]
This isn't obvious, so let's take a moment to understand it. First off, remember
that everything in this diagram is a chart; it is \emph{not} a diagram in the
double category of arenas, but in the category $\Cat{Chart}$ of charts. Now, we
can ask what it means for this diagram to commute. First, the bottom part of the
top square must commute: but this just means that $h = f$! Then the bottom part
of the bottom square means that $g = w \circ h$, or $g = w \circ f$. Now, the
top part of the bottom square says that $h_{\flat}(f(i), o) = g_{\flat}(i, o)$,
and the top part of the top square says that 

\end{proof}
\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{example}
  Let's see what happens when we take the functor
  $\Cat{Chart}_{\determ}\left(  \littlelens{I}{O}, -\right)$ for the arena
  $\littlelens{\ord{1}}{\ord{1}}$. A chart $\lens{a^-}{a^+} :
  \lens{\ord{1}}{\ord{1}} \tto \lens{A^-}{A^+}$ is just a pair of elements $a^-
  \in A^-$ and $a^+ \in A^+$, so
$$\Cat{Chart}_{\determ}\left( \littlelens{\ord{1}}{\ord{1}}, \littlelens{A^-}{A^+} \right) = A^-
\times A^+.$$
Now, if we have a lens $\lens{w^{\sharp}}{w} : \lens{A^-}{A^+} \fromto
\lens{B^-}{B^+}$, we have a square 
\[
    \begin{tikzcd}
      \lens{\ord{1}}{\ord{1}} \ar[r, shift left, "\lens{a^-}{a^+}"] \ar[r, shift
      right] \ar[d, shift right, equals] \ar[d, shift left, equals] &
      \lens{A^-}{A^+} \ar[d, shift left, leftarrow,
      "\lens{w^{\sharp}}{w}"] \ar[d, shift right]\\
      \lens{\ord{1}}{\ord{1}} \ar[r, shift right, "\lens{b^-}{b^+}"'] \ar[r,
      shift left] & \lens{B^-}{B^+}
    \end{tikzcd}
\]
if and only if $w(a^+) = b^+$ and $w^{\sharp}(a^+, b^-) = a^-$. Thinking of
$\lens{w^{\sharp}}{w}$ as a wiring diagram, this would mean that $b^+$ is that
part of $a^+$ which is passed forward on the outgoing wires, and $a^-$ is the
inner input which comes from the inner output $a^+$ and outer input $b^-$.

To take a concrete example, suppose that $\lens{w^{\sharp}}{w}$ were the
following wiring diagarm:
\[
\begin{tikzpicture}[oriented WD, every fit/.style={inner xsep=\bbx, inner ysep=\bby}, bbx = .3cm, bby =.3cm, bb min width=.5cm, bb port length=2pt, bb port sep=1, baseline=(S'.center)]
	\node[bb={2}{2}, fill=blue!10, dashed] (S) {};

  \node[bb={0}{0}, fit={($(S.north east) + (1,1)$) ($(S.south west) - (1,0)$)}] (S') {};
  
  \draw (S_out2) to (S_out2-|S'.east);
  \draw (S_in2-|S'.west) to (S_in2);

  \draw let \p1=(S.north east), \p2=(S.north west), \n1={\y2+\bby}, \n2=\bbportlen in    (S_out1) to[in=0] (\x1 +\n2, \n1) -- (\x2-\n2, \n1) to[out=180] (S_in1);
\end{tikzpicture}
\]
That is, let's take $A^+ = X \times Y$ and $A^- = X \times Z$, and $B^+ = Y$
and $B^- = Z$, and
\begin{align*}
w(x, y) &= y \\
w^{\sharp}((x, y), z) &= (x, z).
\end{align*}
Using the definition above, we can calculate the resulting matrix $\Cat{Chart}_{\determ}\left( \lens{I}{O},
  \lens{w^{\sharp}}{w} \right)$ as having $( ((x, y), (x', z)), (y', z')
)$-entry
\[\begin{cases} \ord{1} &\mbox{if $w(x, y) = y'$ and $w^{\sharp}((x, y), z) =
    (x', z')$} \\ \emptyset &\mbox{otherwise.} \end{cases}
\]
or, by the definition of $\lens{w^{\sharp}}{w}$, 
\[\begin{cases} \ord{1} &\mbox{if $x = x'$, $y = y'$, and $z = z'$} \\ \emptyset
    &\mbox{otherwise.}\end{cases}
\]
  which was the definition of $\Fun{Tr}^{X}$ given in \cref{prop.trace_multiplying_by_matrix}!
\end{example}

\begin{exercise}
Let $\lens{w^{\sharp}}{w} : \lens{A \times B}{B \times C} \fromto \lens{A}{C}$
be the wiring diagram 
\[
\begin{tikzpicture}[oriented WD, bbx = .3cm, bby =.3cm, bb min width=.5cm, bb port length=2pt, bb port sep=1, every fit/.style={inner xsep=\bbx, inner ysep=\bby}
, baseline=(Outer.center)]
  \node[bb={1}{1}, fill=blue!10] (S1) {};
  \node[bb={1}{1}, fill=blue!10, right= of S1] (S2) {};

  \node[bb={1}{1}, fit={(S1) (S2)}] (Outer) {};

  \draw (Outer_in1) to (S1_in1);
  \draw (S1_out1) to (S2_in1);
  \draw (S2_out1) to (Outer_out1);
\end{tikzpicture}
\] 
Calculate the entries of the matrix $\Cat{Chart}_{\determ}\left( \lens{\ord{1}}{\ord{1}}, \lens{w^{\sharp}}{w} \right)$.
\end{exercise}

By the functoriality of \cref{prop.lens_to_matrix_functor_discrete}, we can
calculate the matrix of a big wiring diagram by expressing it in terms of a
series of traces, and mutliplying the resulting matrices together. This means
that the process of multiplying, tensoring, and tracing matrices described by a
wiring diagram is well described by the matrix we constructed in
\cref{prop.lens_to_matrix_functor_discrete}, since we already know that it
interprets the basic wiring diagrams correctly.

 But we are also interested in charts, since we have to chart out our
behaviors. So we will give a \emph{double functor} $\Cat{Arena}_{\determ} \to
\Cat{Matrix}$ that tells us not only how to turn a lens into a matrix, but also
how this operation interacts with charts. This is an example of a
\emph{representable} double functor.


We will first define the double functor $\Cat{Arena}_{\determ}\left( \lens{I}{O}, -
\right) : \Cat{Arena}_{\determ} \to \Cat{Matrix}$ represented by an arena $\lens{I}{O}$
explicitly. Then we will see how this argument can be abstracted to a double
category which satisfies a horizontal factorization property.

\begin{proposition}\label{prop.representable_double_functor}
  There is a double functor
  $$\Cat{Arena}_{\determ}\left( \littlelens{I}{O}, -
\right) : \Cat{Arena} \to \Cat{Matrix}$$
which acts in the following way:
\begin{itemize}
  \item An arena $\lens{A^-}{A^+}$ gets sent to the set $\Cat{Chart}_{\determ}\left(
      \lens{I}{O}, \lens{A^-}{A^+} \right)$ of charts from $\lens{I}{O}$ to $\lens{A^-}{A^+}$.
  \item The vertical functor is $\Cat{Chart}\left( \lens{I}{O}, - \right) :
    \Cat{Lens} \to \Cat{Matrix}$ from \cref{prop.lens_to_matrix_functor_discrete}.
  \item The horizontal functor is the representable functor $\Cat{Arena}\left(
      \lens{I}{O}, - \right) : \Cat{Arena} \to \smset$ which acts on a chart
    $\lens{f_{\flat}}{f} : \lens{A^-}{A^+} \tto \lens{B^-}{B^+}$ by
    post-composition.
  \item To a square
    \[ \beta = 
      \begin{tikzcd}
        \littlelens{A^-}{A^+} \ar[r, shift left, "\littlelens{f_{\flat}}{f}"] \ar[r, shift
        right] \ar[d, shift right, "\littlelens{j^{\sharp}}{j}"'] \ar[d, shift left,
        leftarrow] & \littlelens{B^-}{B^+} \ar[d, shift left, leftarrow,
        "\littlelens{k^{\sharp}}{k}"] \ar[d, shift right]\\
        \littlelens{C^-}{C^+} \ar[r, shift right, "\littlelens{g^{\sharp}}{g}"'] \ar[r,
        shift left] & \littlelens{D^-}{D^+}
      \end{tikzcd}
    \]
    in the double category of arenas, we give the square
        \[\Cat{Arena}_{\determ}\left(\littlelens{I}{O}, \beta \right)  =\]
        \[
      \begin{tikzcd}[sep = large]
        \Cat{Arena}_{\determ}\left(\littlelens{I}{O}, \littlelens{A^-}{A^+} \right) \ar[r, "{\Cat{Arena}_{\determ}\left(\littlelens{I}{O}, \littlelens{f_{\flat}}{f} \right)}"]  \ar[d, "{\Cat{Arena}_{\determ}\left(\littlelens{I}{O}, \littlelens{j^{\sharp}}{j} \right)}"'] 
         &  \Cat{Arena}_{\determ}\left(\littlelens{I}{O}, \littlelens{B^-}{B^+} \right)\ar[d,
        "{ \Cat{Arena}_{\determ}\left(\littlelens{I}{O}, \littlelens{k^{\sharp}}{k} \right) }"] \\
   \Cat{Arena}_{\determ}\left(\littlelens{I}{O}, \littlelens{C^-}{C^+} \right)      \ar[r, "{\Cat{Arena}_{\determ}\left(\littlelens{I}{O}, \littlelens{g_{\flat}}{g_{\flat}} \right)}"']  & \Cat{Arena}_{\determ}\left(\littlelens{I}{O}, \littlelens{D^-}{D^+} \right)
      \end{tikzcd}
    \]
    in the double category of matrices defined by horizontal composition of
    squares in $\Cat{Arena}_{\determ}$ (remember that the entries of these matrices are
    sets of squares in $\Cat{Arena}_{\determ}$, even though that means they either have a
    single element or no elements).
    \begin{align*}
    \Cat{Arena}_{\determ}\left(\littlelens{I}{O}, \beta \right)(\alpha) = \alpha \mid \beta.
\end{align*}
\end{itemize}
\end{proposition}
\begin{proof}
 

We can write the double functor $\Cat{Arena}_{\determ}\left(\littlelens{I}{O}, - \right)$
entirely in terms of the double category $\Cat{Arena}_{\determ}$:
\begin{itemize}
  \item It sends an arena $\lens{A^-}{A^+}$ to the set of charts (horizontal
    maps) $\lens{f_{\flat}}{f} : \lens{I}{O}  \tto \lens{A^-}{A^+}$.
  \item It sends a chart $\lens{g_{\flat}}{g}$ to the map $\lens{f_{\flat}}{f}
    \mapsto \left. \lens{f_{\flat}}{f} \middle| \lens{g_{\flat}}{g} \right.$.
  \item It sends a lens $\lens{w^{\sharp}}{w}$ to the set of squares $\beta :
    \lens{I}{O} \to \lens{w^{\sharp}}{w}$, indexed by their top and bottom
    boundaries.
  \item It sends a square $\alpha$ to the map given by horizontal compostion
    $\beta \mapsto \beta \mid \alpha$.
\end{itemize}

We can see that this double functor (let's call it $F$, for short) takes seriously the idea that ``squares are
charts between lenses'' from
\cref{ex.understanding_squares_in_double_cat_of_arenas}. From this description,
and the functoriality of \cref{prop.lens_to_matrix_functor_discrete}, we can see
that the assignments above satisfy the double functor laws. 
\begin{itemize}
  \item Horizontal functoriality follows from horizontal associativity in
    $\Cat{Arena}_{\determ}$:
$$F(\alpha\mid \beta)(\gamma) = \gamma \mid (\alpha \mid \beta) = (\gamma \mid
\alpha) \mid \beta = F(\alpha) \mid F(\beta) (\gamma).$$
\item Vertical functoriality follows straight from the definitions:
  $$F\left( \frac{\alpha}{\beta} \right)(\_, \gamma, \delta) = (\_, \gamma \mid
  \alpha, \delta \mid \beta) = \frac{F(\alpha)(\gamma)}{F(\beta)(\delta)}.$$
\item It's pretty straightforward to check that identities get sent to identities.
\end{itemize}
\end{proof}

This construction is an example of a more general notion of \emph{representable
  double functor}. Using the general notion, we can construct a similar double functor
$$\Cat{Arena}_{\dd}\left( \littlelens{I}{O}, - \right) : \Cat{Arena}_{\dd} \to
\Cat{Matrix}$$
for any systems theory $\dd$.
Unlike for categories, not all objects in all double
categories admit representable double functors\footnote{Any object in a double
  category does admit a representable \emph{lax} double functor, but we won't
  need any of these and so won't introduce this notion.}. There is a small
condition on an object: the \emph{horizontal factor condition}.
\begin{definition}\label{defn:spanlike}
  Let $\cat{D}$ be a double category. An object $D$ of $\cat{D}$ satisfies the
  \emph{horizontal factor condition} when for any square 
\[
        \begin{tikzcd}[column sep=tiny]
          D \ar[dd, equals] \ar[rr, "f_1"] & & X_1 \ar[d, "k_1"] \\
           & \alpha & X_2 \ar[d, "k_2"]\\
          D \ar[rr, "f_3"'] & & X_3
        \end{tikzcd}
        \]
  there is a unique triple of a horizontal $f_2 : D \to X_2$ and squares
  $\alpha_1 : D \Rightarrow k_1$ and $\alpha_2 : D \Rightarrow k_2$ so that
\[
        \begin{tikzcd}[column sep=tiny]
          D \ar[dd, equals] \ar[rr, "f_1"] & & X_1 \ar[d, "k_1"] \\
           & \alpha & X_2 \ar[d, "k_2"]\\
          D \ar[rr, "f_3"'] & & X_3
        \end{tikzcd}
        \quad=\quad
       \begin{tikzcd}[sep = tiny]
	D && {X_1} \\
	& {\alpha_1} \\
	D && {X_2} \\
	& {\alpha_2} \\
	D && {X_3}
	\arrow[from=1-1, to=3-1, equals]
	\arrow[from=3-1, to=5-1, equals]
	\arrow["{f_1}", from=1-1, to=1-3]
	\arrow["{f_2}", from=3-1, to=3-3]
	\arrow["{f_3}"', from=5-1, to=5-3]
	\arrow["{k_1}", from=1-3, to=3-3]
	\arrow["{k_2}", from=3-3, to=5-3]
\end{tikzcd} 
\]
 We say that $\cat{D}$ is \emph{spanlike} if every $D$ satisfies the horizontal
 factor condition. 
\end{definition}

\begin{theorem}\label{thm:representable.double.functor}
  Let $\cat{D}$ be a double category and let $D$ be an object of $\cat{D}$
  satisfying the horizontal factor condition. Then there is a
  \emph{representable double functor} $\cat{D}(D, -) : \cat{D} \to \Cat{Matrix}$
  defined as follows:
  \begin{itemize}
    \item For an object $X$, $\cat{D}(D, X)$ is the set of horizontal arrows $D
      \to X$.
    \item For a horizontal $g : X \to Y$, $\cat{D}(D, g) : \cat{D}(D, X) \to
      \cat{D}(D, Y)$ is given by post-composition with $g$: $f \mapsto f \mid g$.
    \item For a vertical $k : X \to Y$, we get the matrix of sets $\cat{D}(D, k)
      : \cat{D}(D, X) \times \cat{D}(D, Y) \to \smset$ given by
      \[
        (f_1, f_2) \mapsto \left\{\mbox{The set of squares}
        \begin{tikzcd}[sep=tiny]
          D \ar[dd, equals] \ar[rr, "f_1"] & & Y \ar[dd, "k"] \\
           & \alpha & \\
          D \ar[rr, "f_2"'] & & Y  
        \end{tikzcd}
        \right\}
      \]
    \item For any square
      \[
        \begin{tikzcd}[sep=tiny]
          X_1 \ar[dd, "k_1"'] \ar[rr, "g_1"] & & Y_1 \ar[dd, "k_2"] \\
           & \alpha & \\
          Y_1 \ar[rr, "g_2"'] & & Y_2  
        \end{tikzcd}
      \]
      we define $\cat{D}(D, \beta)$ to be the map of matrices given by
      post-composing with $\beta$. That is,
      $$\cat{D}(D, \beta)(\alpha) = \alpha \mid \beta.$$
  \end{itemize}
\end{theorem}
\begin{proof}
We will show that this is a double functor. The horizontal component is
functorial since it is the functor $h\cat{D} \to \smset$ represented by $D$. 

For vertical functoriality, we need to show that
$$\cat{D}\left( D, \frac{k_1}{k_2} \right) \cong \frac{\cat{D}(D,
  k_1)}{\cat{D}(D, k_2)}$$
for vertical arrows $k_1 : X_1 \to X_2$ and $k_2 : X_2 \to X_3$. There is always
a map
$$\frac{\cat{D}(D,
  k_1)}{\cat{D}(D, k_2)} \to \cat{D}\left( D, \frac{k_1}{k_2} \right)$$
given by taking two squares and composing them. That this map is a
bijection is a restatement of the horizontal factor condition which we assumed
that $D$ satisfied. The right hand side is the $\cat{D}(D, X_1) \times
\cat{D}(D, X_3)$-matrix of sets which between $f_1$ and $f_3$ is the set
$$\sum_{f_2 \in \cat{D}(D, X_2)} \cat{D}(D, k_1)_{f_1, f_2} \times \cat{D}(D,
k_2)_{f_2, f_3}.$$
So to say that for any $\alpha \in \cat{D}\left( D,  \frac{k_1}{k_2} \right)$
there exists a unique triple $(f_2, \alpha_1, \alpha_2)$ with $\alpha =
\frac{\alpha_1}{\alpha_2}$ is precisely to say that the map which composes two
squares $\alpha_1$ and $\alpha_2$ into $\frac{\alpha_1}{\alpha_2}$ is a bijection.

We then need to check vertical and horizontal functoriality for squares.
Horizontal functoriality of squares comes down to associativity of horizontal
composition, and vertical functoriality of squares comes down to the interchange law.
\end{proof}

\cref{thm:representable.double.functor} gives us
\cref{prop.representable_double_functor} as a special case since the double
category $\Cat{Arena}_{\dd}$ of arenas in any systems theory $\dd$ is \emph{spanlike} --- every arena
$\lens{I}{O}$ satisfies the horizontal factor condition.

\begin{lemma}\label{lem:arena.is.spanlike}
For any systems theory $\dd$, the double category $\Cat{Arena}_{\dd}$ of arenas in
$\dd$ is spanlike: every arena satisfies the horizontal factor condition.
\end{lemma}
\begin{proof}
Fix an arena $\lens{I}{O}$ and suppose that we have a square like so:
\[
\alpha =
  \begin{tikzcd}
    \lens{I}{O} \ar[r, shift left, "\lens{f_{\flat}}{f}"] \ar[r, shift right] \ar[dd, shift right,
    equals] \ar[dd, shift left, equals] &
    \lens{A^-}{A^+} \ar[d, shift left, leftarrow,
    "\lens{w^{\sharp}}{w}"] \ar[d, shift right]\\
     & \lens{B^-}{B^+} \ar[d, shift left, leftarrow,
        "\lens{v^{\sharp}}{v}"] \ar[d, shift right]\\
    \lens{I}{O} \ar[r, shift right, "\lens{h_{\flat}}{h}"']
    \ar[r, shift left] & \lens{C^-}{C^+} 
  \end{tikzcd}
\]
Explicitly, this means that we have commuting squares
\begin{equation}\label{eqn:arena.is.spanlike.sqs}
\begin{tikzcd}
	O & {A^+} \\
	& {B^+} \\
	O & {C^+}
	\arrow["f", from=1-1, to=1-2]
	\arrow["h"', from=3-1, to=3-2]
	\arrow["w", from=1-2, to=2-2]
	\arrow["v", from=2-2, to=3-2]
	\arrow[from=1-1, to=3-1, equals]
\end{tikzcd}
\quad\quad
\begin{tikzcd}
	I && I \\
	{h^{\ast}C^-} & {f^{\ast}w^{\ast}v^{\ast}C^-} & {f^{\ast}A^-}
	\arrow[from=1-1, to=1-3, equals]
	\arrow["{h_{\flat}}"', from=1-1, to=2-1]
	\arrow[from=2-1, to=2-2, equals]
	\arrow["{f^{\ast}(w^{\ast}v^{\sharp}\then w^{\sharp})}"', from=2-2, to=2-3]
	\arrow["{f_{\flat}}", from=1-3, to=2-3]
\end{tikzcd}
\end{equation}
We then get a chart
$$\lens{h_{\flat} \then f^{\ast}w^{\ast}v^{\sharp}}{f \then w} : \lens{I}{O}
\rightrightarrows \lens{B^-}{B^+}.$$
This chart fits into two squares like so:
\[
  \begin{tikzcd}[column sep = large]
    \lens{I}{O} \ar[r, shift left, "\lens{f_{\flat}}{f}"] \ar[r, shift right] \ar[d, shift right,
    equals] \ar[d, shift left, equals] &
    \lens{A^-}{A^+} \ar[d, shift left, leftarrow,
    "\lens{w^{\sharp}}{w}"] \ar[d, shift right]\\
     \lens{I}{O} \ar[r, shift left, "{\lens{h_{\flat} \then f^{\ast}w^{\ast}v^{\sharp}}{f
     \then w}}"] \ar[r, shift right] \ar[d, shift right,
    equals] \ar[d, shift left, equals] & \lens{B^-}{B^+} \ar[d, shift left, leftarrow,
        "\lens{v^{\sharp}}{v}"] \ar[d, shift right]\\
    \lens{I}{O} \ar[r, shift right, "\lens{h_{\flat}}{h}"']
    \ar[r, shift left] & \lens{C^+}{C^-} 
  \end{tikzcd}
\]
The bottom half of the top square and the top half of the bottom square commute
by definition. The bottom half of the bottom square asks that $f \then w \then v
= h$, but this is precisely the bottom half of $\alpha$. The top half of the top
square asks that the following diagram commute:
\[\begin{tikzcd}
	I & I \\
	{h^{\ast}C^-} \\
	{f^{\ast}w^{\ast}v^{\ast}C^-} \\
	{f^{\ast}w^{\ast}B^-} & {f^{\ast}A^-}
	\arrow[from=1-1, to=1-2, equals]
	\arrow["{f_{\flat}}", from=1-2, to=4-2]
	\arrow["{h_{\flat}}"', from=1-1, to=2-1]
	\arrow[from=2-1, to=3-1, equals]
	\arrow["{f^{\ast}w^{\ast}v^{\sharp}}"', from=3-1, to=4-1]
	\arrow["{f^{\ast}w^{\sharp}}"', from=4-1, to=4-2]
\end{tikzcd}\]
This is a rearrangement of the second square in Diagram
\ref{eqn:arena.is.spanlike.sqs}.

Because we have just rearranged the data of the big outer square $\alpha$, this
factorization of $\alpha$ is \emph{unique}.
\end{proof}

As a corollary, \cref{thm:representable.double.functor} gives us a representable
double functor
$$\Cat{Arena}_{\dd}\left( \littlelens{I}{O}, - \right) : \Cat{Arena}_{\dd} \to
\Cat{Matrix}$$
in any systems theory $\dd$. So we can turn any lens in any systems theory into a matrix in
a way that preserves the composition of lenses.
\begin{theorem}\label{thm:representable.dbl.fun.doctrine}
  For any systems theory $\dd$ and any arena $\lens{I}{O}$, there is a representable
  double functor
  $$\Cat{Arena}_{\dd}\left( \littlelens{I}{O}, - \right) : \Cat{Arena}_{\dd} \to \Cat{Matrix}.$$
\end{theorem}


\subsection{How behaviors of systems wire together: representable doubly indexed functors}

We now come to the mountaintop. It's been quite a climb, and we're almost there.

We can now describe all the ways that behaviors of systems get put together when
we wire systems together. There are a bunch of laws governing how behaviors get
put together, and we organize them all into the notion of a \emph{lax doubly
  indexed functor}. To any system $\Sys{T}$ in a systems theory $\dd$, we will give a lax doubly indexed
functor
$$\Fun{Behave}_{\Sys{T}} : \Cat{Sys}_{\dd} \to \Cat{Vec}.$$

Since behaviors of shape $\Sys{T}$ are a sort of map out of $\Sys{T}$, we may
think of $\Fun{Behave}_{\Sys{T}}$ as a \emph{representable} lax doubly indexed
functor. 


\begin{theorem}\label{thm.representable_discrete}
  For any systems theory $\dd$ and any system $\Sys{T}$ in $\dd$, there is a lax doubly indexed functor
$\Fun{Behave}_{\Sys{T}} : \Cat{Sys}_{\dd} \to \Cat{Vec}$
which sends systems to their sets of $\Sys{T}$-shaped behaviors.
\[\begin{tikzcd}
	{\Cat{Arena}_{\dd}} \\
	&& {\Cat{Cat}} \\
	{\Cat{Matrix}}
	\arrow[""{name=0, anchor=center, inner sep=0}, "{\Cat{Sys}_{\dd}}", from=1-1,
  to=2-3, bend left = 10]
	\arrow[""{name=1, anchor=center, inner sep=0}, "{\Cat{Vec}}"', from=3-1,
  to=2-3, bend right = 10]
	\arrow["{\Cat{Arena}_{\dd}\left(\littlelens{\In{T}}{\Out{T}},-\right)}"', from=1-1, to=3-1]
	\arrow["{\Fun{Behave}_{\Sys{T}}}"', shorten <=4pt, shorten >=4pt, Rightarrow, from=0, to=1]
\end{tikzcd}\]
\end{theorem}

Let's see what this theorem is really asking for while we construct it. As with
many of the constructions we have been seeing, the hard part is understanding
what we are supposed to be constructing; once we do that, the answer will always
be ``compose in the appropriate way in the appropriate double category''.
\begin{itemize}
  \item First, we need $\Fun{Behave}_{\Sys{T}}^0 : \Cat{Arena} \to
    \Cat{Matrix}$ which send an arena to the set of charts from
    $\lens{\In{T}}{\Out{T}}$ to that arena. It will send a chart to the function
    given by composing with that chart, and it will send a lens to a matrix that
    describes the wiring pattern in that lens. We've seen how to do this in \cref{thm:representable.dbl.fun.doctrine}:
    $$\Fun{Behave}^0_{\Sys{T}} = \Cat{Arena}\left( \littlelens{\In{T}}{\Out{T}},
      -\right)$$
This is the blueprint for how our systems will compose.
  \item Next, for any arena $\lens{I}{O}$, we need a functor
    \[\Fun{Behave}_{\Sys{T}}^{\littlelens{I}{O}} :
    \Cat{Sys}\littlelens{I}{O} \to \Cat{Vec}\left( \Cat{Arena}\left( \littlelens{\In{T}}{\Out{T}},
      \littlelens{I}{O}\right) \right)\]
    which will send a system $\Sys{S}$ with interface $\lens{I}{O}$ to its
    set of behaviors of shape $\Sys{T}$, indexed by their chart. That is, we
    make the following definition:
   \[
\Fun{Behave}_{\Sys{T}}^{\littlelens{I}{O}}(\Sys{S})_{\littlelens{f_{\flat}}{f}}
\coloneqq \Cat{Sys}\littlelens{f_{\flat}}{f}(\Sys{T}, \Sys{S}). 
\]
This is functorial by horizontal associativity of squares in $\Cat{Arena}$.
\item For any lens $\lens{w^{\sharp}}{w} : \lens{I}{O} \fromto \lens{I'}{O'}$,
  we need a natural transformation
  \[
    \begin{tikzcd}
\Cat{Sys}\lens{I}{O} \ar[dd, "{\Cat{Sys}\littlelens{w^{\sharp}}{w}}"'] \ar[rr, "{\Fun{Behave}_{\Sys{T}}^{\littlelens{I}{O}}}"] & & \Cat{Vec}\left( \Cat{Arena}\left(
    \littlelens{\In{T}}{\Out{T}}, \littlelens{I}{O} \right) \right) \ar[dd, "{\Cat{Vec}\left(
  \Cat{Arena}\left( \littlelens{\In{T}}{\Out{T}}, \littlelens{w^{\sharp}}{w}
  \right)\right)}"] \ar[ddll, Rightarrow, "{\Fun{Behave}_{\Sys{T}}^{\littlelens{w^{\sharp}}{w}}}"']\\
 & & \\
\Cat{Sys}\lens{I'}{O'}  \ar[rr, "{\Fun{Behave}_{\Sys{T}}^{\littlelens{B^-}{B^+}} }"']& & \Cat{Vec}\left( \Cat{Arena}\left(
    \littlelens{\In{T}}{\Out{T}}, \littlelens{I}{O} \right) \right) \\
    \end{tikzcd}
\]
This will take any behaviors of component systems whose charts compatible
according to the wiring pattern of $\lens{w^{\sharp}}{w}$ and wire them together
into a behavior of the wired together systems. In other words, this will be
given by vertical composition of squares in $\Cat{Arena}$. To see how that
works, we need follow a $\lens{I}{O}$-system $\Sys{S}$ around this diagram and see
how this natural transformation can be described so simply. Following $\Sys{S}$
around the top path of the diagram gives us the following vector of sets, we
first send $\Sys{S}$ to the vector of sets
\begin{align*}
\littlelens{f_{\flat}}{f} : \littlelens{\In{T}}{\Out{T}} \tto \littlelens{I}{O}
&\mapsto \Cat{Sys}\littlelens{f_{\flat}}{f}(\Sys{T}, \Sys{S}) \\
&= \left\{  
    \begin{tikzcd}[ampersand replacement = \&]
      \lens{\State{T}}{\State{T}} \ar[r, shift left, dashed, "\lens{T\phi}{\phi}"] \ar[r, dashed, shift right] \ar[d, shift right,
      "\lens{\update{T}}{\expose{T}}"'] \ar[d, shift left, leftarrow] \&
      \lens{\State{S}}{\State{S}} \ar[d, shift left, leftarrow,
      "\lens{\update{S}}{\expose{S}}"] \ar[d, shift right]\\
      \lens{\In{T}}{\Out{T}} \ar[r, shift right, "\lens{f^{\sharp}}{f}"'] \ar[r,
      shift left] \& \lens{I}{O}
    \end{tikzcd}
\right\}
\end{align*}
We then multiply this by the matrix \(\Cat{Arena}\left(
  \littlelens{\In{T}}{\Out{T}}, \littlelens{w^{\sharp}}{w} \right)\) to get the
vector of sets whose entries are pairs of the following form:
\begin{align*}
\littlelens{g_{\flat}}{g} : \littlelens{\In{T}}{\Out{T}} \tto \littlelens{I'}{O'}
&\mapsto \left\{    
    \begin{tikzcd}[ampersand replacement = \&]
      \lens{\In{T}}{\Out{T}} \ar[r, shift left, dashed, "\lens{f_{\flat}}{f}"] \ar[r, dashed, shift right] \ar[d, shift right,
      equals] \ar[d, shift left, equals] \&
      \lens{I}{O} \ar[d, shift left, leftarrow,
      "\lens{w^{\sharp}}{w}"] \ar[d, shift right]\\
      \lens{\In{T}}{\Out{T}} \ar[r, shift right, "\lens{g_{\flat}}{g}"'] \ar[r,
      shift left] \& \lens{I'}{O'}
    \end{tikzcd}, \quad
    \begin{tikzcd}[ampersand replacement = \&]
      \lens{\State{T}}{\State{T}} \ar[r, shift left, dashed, "\lens{T\phi}{\phi}"] \ar[r, dashed, shift right] \ar[d, shift right,
      "\lens{\update{T}}{\expose{T}}"'] \ar[d, shift left, leftarrow] \&
      \lens{\State{S}}{\State{S}} \ar[d, shift left, leftarrow,
      "\lens{\update{S}}{\expose{S}}"] \ar[d, shift right]\\
      \lens{\In{T}}{\Out{T}} \ar[r, shift right, "\lens{f_{\flat}}{f}"'] \ar[r,
      shift left] \& \lens{I}{O}
    \end{tikzcd}
\right\}
\end{align*}
On the other hand, following $\Sys{S}$ along the bottom path has us first composing it vertically with $\lens{w^{\sharp}}{w}$ and then finding the behaviors in it:
\[
\littlelens{g_{\flat}}{g} : \littlelens{\In{T}}{\Out{T}} \tto \littlelens{I'}{O'}
\mapsto \left\{  
    \begin{tikzcd}[ampersand replacement = \&]
      \lens{\State{T}}{\State{T}} \ar[r, shift left, dashed, "\lens{T\phi}{\phi}"] \ar[r, dashed, shift right] \ar[d, shift right,
      "\lens{\update{T}}{\expose{T}}"'] \ar[d, shift left, leftarrow] \&
      \lens{\State{S}}{\State{S}} \ar[d, shift left, leftarrow,
      "\lens{\update{S}}{\expose{S}}\then \lens{w^{\sharp}}{w}"] \ar[d, shift right]\\
      \lens{\In{T}}{\Out{T}} \ar[r, shift right, "\lens{g_{\flat}}{g}"'] \ar[r,
      shift left] \& \lens{I'}{O'}
    \end{tikzcd} 
\right\}
\]

  Finally, we are ready to define our natural transformation from the virst
  vector of sets to the second using vertical composition:
  \[
\Fun{Behave}_{\Sys{T}}^{\littlelens{w^{\sharp}}{w}}(\Sys{S})_{\littlelens{g_{\flat}}{g}}(\square_{w}, \phi) = \frac{\phi}{\square_w}.
  \]
  That this is natural for behaviors $\psi : \Sys{S} \to \Sys{U}$ in $\Cat{Sys}\lens{I}{O}$ follows quickly from the horizontal identity and interchange laws in $\Cat{Arena}$:
  \begin{align*}
    \frac{\phi \mid \psi}{\square_{w}} &= \frac{\phi \mid \psi}{\square_{w} \mid \littlelens{w^{\sharp}}{w}} \\
                                  &= \left. \frac{\phi}{\square_{w}} \,\middle|\, \frac{\psi}{\littlelens{w^{\sharp}}{w}} \right. .
  \end{align*}


\item For any chart $\lens{g_{\flat}}{g} : \lens{I}{O} \tto
  \lens{I'}{O'}$, we need a square
  \[
\begin{tikzcd}
  \Cat{Sys}\littlelens{I}{O} \ar[dd,
  "{\Fun{Behave}_{\Sys{T}}^{\littlelens{I}{O}}}"'] \ar[rr, tick,
  "{\Cat{Sys}\littlelens{g_{\flat}}{g}}"] & & \Cat{Sys}\littlelens{I'}{O'} \ar[dd, "{\Fun{Behave}_{\Sys{T}}^{\littlelens{I'}{O'}}}"]\\
  & \Fun{Behave}_{\Sys{T}}^{\littlelens{g_{\flat}}{g}} & \\
   \Cat{Vec}\left( \Cat{Arena}\left( \littlelens{\In{T}}{\Out{T}},
      \littlelens{I}{O}\right) \right) \ar[rr, tick, "{\Cat{Vec}\left( \Cat{Arena}\left( \littlelens{\In{T}}{\Out{T}},
      \littlelens{g_{\flat}}{g}\right) \right)}"']& & \Cat{Vec}\left( \Cat{Arena}\left( \littlelens{\In{T}}{\Out{T}},
      \littlelens{I'}{O'}\right) \right)
\end{tikzcd}
\]
This will take any behavior from $\Sys{S}$ to $\Sys{U}$ with chart $\lens{g_{\flat}}{g}$ and give the
function which takes behaviors of shape $\Sys{T}$ in $\Sys{S}$ and gives the
composite behavior of shape $\Sys{T}$ in $\Sys{U}$. That is,
$$\Fun{Behave}_{\Sys{T}}^{\littlelens{g_{\flat}}{g}}(\Sys{S}, \Sys{U})(\psi) =
\phi \mapsto \phi \mid \psi.$$
The naturality of this assignment follows from horizontal associativity in $\Cat{Arena}$.
\end{itemize}



Its a bit scary to see written out with all the names and symbols, but the idea
is simple enough. We are composing two sorts of things: behaviors and systems.
If we have some behaviors of shape $\Sys{T}$ in our systems and their charts are
compatible with a wiring pattern, then we get a behavior of the wired together
system. If we have a chart, then behaviors with that chart give us a way of
mapping forward behaviors of shape $\Sys{T}$. 

The lax doubly indexed functor laws now tell us some facts about how these two
sorts of composition interact.
\begin{itemize}
  \item (Vertical Lax Functoriality) This asks us to suppose that we are wiring
    our systems together in two stages. The law then says that if we take a
    bunch of behaviors whose charts are compatible for the total wiring pattern
    and wire them together into a behavior of the whole system, this is the same
    behavior we get if we first noticed that they were compatible for the first
    wiring pattern, wired them together, then noticed that the result was
    compatible for the second wiring pattern, and wired that together. This
    means that nesting of wiring diagrams commutes with finding behaviors of our systems.
  \item (Horizontal Functoriality) This asks us to suppose that we have two
    charts and a behavior of each. The law then says that composing a behavior
    of shape $\Sys{T}$ with the composite of those behaviors is the same as composing
    it with the first one and then with the second one.
  \item (Functorial Interchange) This asks us to suppose that we have a pair of
    wiring patterns and compatible charts between them (a square in $\Cat{Arena}$). The law then says that if we
    take a bunch of behaviors whose charts are compatable according to the first
    wiring pattern, wire them together, and then compose with a behavior of the
    second chart, we get the same thing as if we compose them all with behaviors
    of the first chart, noted that they were compatible with the second wiring
    pattern, and then wired them together.
\end{itemize}

Though it seems like it would be a mess of symbols to check these laws, they in
fact fall right out of the laws for the double categories of arenas and
matrices, and the functoriality of \cref{prop.representable_double_functor}.
That is, we've already built up all the tools we need to prove this fact, we
just need to finish proving that $\Fun{Behave}_{\Sys{T}}$ is a lax doubly indexed functor.

\begin{itemize}
  \item (Vertical Lax Functoriality) Suppose we have composable lenses
    $\lens{w^{\sharp}}{w} : \lens{I_1}{O_1} \fromto \lens{I_2}{O_2}$ and
    $\lens{u^{\sharp}}{u} : \lens{I_2}{O_2} \fromto \lens{I_3}{O_3}$. We need to
    show that
    $$\Fun{Behave}_{\Sys{T}}^{\littlelens{w^{\sharp}}{w} \then
      \littlelens{u^{\sharp}}{u}} = \left( \Fun{Behave}_{\Sys{T}}^{
        \littlelens{u^{\sharp}}{u}} \Cat{Sys}\littlelens{w^{\sharp}}{w} \right)
    \circ \left(
\Cat{Vec}\Cat{Arena}\left( \littlelens{\In{T}}{\Out{T}}, \littlelens{u^{\sharp}}{u} \right)
\Fun{Behave}_{\Sys{T}}^{\littlelens{w^{\sharp}}{w}}  \right).$$
This follows immediately from vertical associativity in $\Cat{Arena}$, once both
sides have been expanded out. 
 Let $\Sys{S}$ be a $\lens{I_1}{O_1}$-system, then 
\begin{align*}
  \Fun{Behave}_{\Sys{T}}^{\littlelens{w^{\sharp}}{w} \then
      \littlelens{u^{\sharp}}{u}} (\Sys{S})(\alpha, \phi) &=   \Fun{Behave}_{\Sys{T}}^{\littlelens{w^{\sharp}}{w} \then
      \littlelens{u^{\sharp}}{u}} (\Sys{S})\left(  \frac{\beta}{\gamma}, \phi\right) &\mbox{by \cref{prop.lens_to_matrix_functor_discrete},}\\
  &= \frac{\phi}{\frac{\beta}{\gamma}} \\
&= \frac{\frac{\phi}{\beta}}{\gamma} \\
&= \left( \Fun{Behave}_{\Sys{T}}^{
        \littlelens{u^{\sharp}}{u}} \Cat{Sys}\littlelens{w^{\sharp}}{w} \right)
    \circ \left(
\Cat{Arena}\left( \littlelens{\In{T}}{\Out{T}}, \littlelens{u^{\sharp}}{u} \right)
\Fun{Behave}_{\Sys{T}}^{\littlelens{w^{\sharp}}{w}}  \right)(\gamma, \beta, \phi).
\end{align*}
\item (Horizontal Functoriality) This follows directly from horizontal associativity in $\Cat{Arena}$.
\item (Functorial Interchange) This law will follow directly from interchange in
  the double category of arenas. Let $\alpha$ be a square in $\Cat{Arena}$ of the
  following form:
\[
  \alpha = 
    \begin{tikzcd}
      \lens{A^-}{A^+} \ar[r, shift left, "\lens{f_{\flat}}{f}"] \ar[r, shift
      right] \ar[d, shift right, "\lens{j^{\sharp}}{j}"'] \ar[d, shift left,
      leftarrow] & \lens{B^-}{B^+} \ar[d, shift left, leftarrow,
      "\lens{k^{\sharp}}{k}"] \ar[d, shift right]\\
      \lens{C^-}{C^+} \ar[r, shift right, "\lens{g^{\sharp}}{g}"'] \ar[r, shift
      left] & \lens{D^-}{D^+}
    \end{tikzcd}
\]
We need to show that
\begin{equation}\label{eqn.interchange_func}
\left.\Fun{Behave}_{\Sys{T}}^{\littlelens{j^{\sharp}}{j}} \,\middle|\,
  \frac{\Cat{Sys}(\alpha)}{\Fun{Behave}_{\Sys{T}}^{\littlelens{g_{\flat}}{g}}}
\right. = \left.
  \frac{\Fun{Behave}_{\Sys{T}}^{\littlelens{f_{\flat}}{f}}}{\Cat{Vec}\Cat{Arena}\left(
        \littlelens{\In{T}}{\Out{T}}, \alpha \right)} \,
    \middle|\, \Fun{Behave}_{\Sys{T}}^{\littlelens{k^{\sharp}}{k}} \right.
\end{equation}
We can see both sides as natural transformations of the signature
\[
  \begin{tikzcd}
    \Cat{Sys}\littlelens{A^-}{A^+} \ar[d,
    "{\Fun{Behave}_{\Sys{T}}^{\littlelens{A^-}{A^+}}}"'] \ar[rr, 
    tick, "{\Cat{Sys}\littlelens{f_{\flat}}{f}}"] & & \Cat{Sys}\littlelens{B^-}{B^+} \ar[d,
    "{\Cat{Sys}\littlelens{k^{\sharp}}{k}}"] \\
    \Cat{Vec}\Cat{Arena}\left( \littlelens{\In{T}}{\Out{T}},
      \littlelens{A^-}{A^+} \right) \ar[d, "{ \Cat{Vec}\Cat{Arena}\left( \littlelens{\In{T}}{\Out{T}},
      \littlelens{j^{\sharp}}{j} \right)}"']& \ref{eqn.interchange_func} & \Cat{Sys}\littlelens{D^-}{D^+}
  \ar[d, "{\Fun{Behave}_{\Sys{T}}^{\littlelens{D^-}{D^+}}}"]\\
     \Cat{Vec}\Cat{Arena}\left( \littlelens{\In{T}}{\Out{T}},
      \littlelens{C^-}{C^+} \right) \ar[rr, tick, "{ \Cat{Vec}\Cat{Arena}\left( \littlelens{\In{T}}{\Out{T}},
      \littlelens{g_{\flat}}{g} \right) }"'] & &  \Cat{Vec}\Cat{Arena}\left( \littlelens{\In{T}}{\Out{T}},
      \littlelens{D^-}{D^+} \right) 
  \end{tikzcd}
\]

So, to show this equality holds, let's start with a behavior $\psi \in \Cat{Sys}\littlelens{f_{\flat}}{f}(\Sys{S}, \Sys{U})$ with chart $\littlelens{f_{\flat}}{f}$. We need to show that
passing this through the left side of \cref{eqn.interchange_func} equals the
result of passing it through the right hand side. On both sides, the result is an element of
\[
\Cat{Vec}\Cat{Arena}\left( \littlelens{\In{T}}{\Out{T}},
      \littlelens{g_{\flat}}{g} \right)\left(\cdots, \cdots  \right)
\]
and is for that reason a function that takes in a pair of the following form:
\[
  (\square_j, \phi) = \left(  
    \begin{tikzcd}[ampersand replacement = \&]
      \lens{\In{T}}{\Out{T}} \ar[r, shift left, dashed, "\lens{a_{\flat}}{a}"] \ar[r, dashed, shift right] \ar[d, shift right,
      equals] \ar[d, shift left, equals] \&
      \lens{A^-}{A^+} \ar[d, shift left, leftarrow,
      "\lens{j^{\sharp}}{j}"] \ar[d, shift right]\\
      \lens{\In{T}}{\Out{T}} \ar[r, shift right, "\lens{c_{\flat}}{c}"'] \ar[r,
      shift left] \& \lens{C^-}{C^+}
    \end{tikzcd}, \quad
    \begin{tikzcd}[ampersand replacement = \&]
      \lens{\State{T}}{\State{T}} \ar[r, shift left, dashed, "\lens{T\phi}{\phi}"] \ar[r, dashed, shift right] \ar[d, shift right,
      "\lens{\update{T}}{\expose{T}}"'] \ar[d, shift left, leftarrow] \&
      \lens{\State{S}}{\State{S}} \ar[d, shift left, leftarrow,
      "\lens{\update{S}}{\expose{S}}"] \ar[d, shift right]\\
      \lens{\In{T}}{\Out{T}} \ar[r, shift right, "\lens{a^{\sharp}}{a}"'] \ar[r,
      shift left] \& \lens{A^-}{A^+}
    \end{tikzcd}
\right)
\]
The left hand side sends this pair to 
\[
\Fun{Behave}_{\Sys{T}}^{\littlelens{g_{\flat}}{g}}
  \big( \Cat{Sys}(\alpha)(\psi) \big)\left(
    \Fun{Behave}_{\Sys{T}}^{\littlelens{j^{\sharp}}{j}}(\square_j, \phi) \right) 
\]
which equals, rather simply:
\[
\left. \frac{\phi}{\square_j} \,\middle|\, \frac{\psi}{\alpha} \right. .
\]
The right hand side sends the pair to
\[
\Fun{Behave}_{\Sys{T}}^{\littlelens{k^{\sharp}}{k}}\left(
  \Cat{Vec}\Cat{Arena}\left( \littlelens{\In{T}}{\Out{T}}, \alpha \right)\left(
    \square_j, \Fun{Behave}_{\Sys{T}}^{\littlelens{f_{\flat}}{f}}(\psi)(\phi) \right) \right)
\]
which equals, rather simply:
\[
\frac{\phi \mid \psi}{\square_j \mid \alpha}.
\]
That these two composites are equal is precisely the interchange law of a double category.


\end{itemize}


While we have phrased this theorem in terms of systems theories, the
proof uses only the structure available to the doubly indexed category
$\Cat{Sys}_{\dd} : \Cat{Arena}_{\dd} \to \Cat{Cat}$ itself. We can therefore state this
theorem entirely abstractly, which we record here.
\begin{theorem}\label{thm:representable.lax.doubly.indexed.functors}
  Let $\cat{A} : \cat{D} \to \Cat{Cat}$ be a doubly indexed category with
  $\cat{D}$ a spanlike double category. Then for any $\Sys{T} \in \cat{A}(D)$,
  there is a \emph{representable} lax doubly indexed functor
\[\begin{tikzcd}
	{\cat{D}} \\
	&& {\Cat{Cat}} \\
	{\Cat{Matrix}}
	\arrow[""{name=0, anchor=center, inner sep=0}, "{\cat{A}}", from=1-1,
  to=2-3, bend left = 10]
	\arrow[""{name=1, anchor=center, inner sep=0}, "{\Cat{Vec}}"', from=3-1,
  to=2-3, bend right = 10]
	\arrow["{\cat{D}\left(D,-\right)}"', from=1-1, to=3-1]
	\arrow["{\cat{A}(\Sys{T}, -)}"', shorten <=4pt, shorten >=4pt, Rightarrow,
  from=0, to=1]
\end{tikzcd}\]
\end{theorem}

\subsection{Is the whole always more than the composite of its parts?}
Unfortunately, $\Fun{Behave}_{\Sys{T}}$ is lax (and not taut) for general
$\Sys{T}$. This means that while behaviors of component systems will induce
behaviors of composite systems, it isn't necessarily the case that all behaviors
of the composite arise this way.

But there is a simple condition we can put on $\Sys{T}$ which will
ensure that $\Fun{Behave}_{\Sys{T}}$ \emph{is} taut, and therefore that we can
recover the behaviors of wired together systems from the behaviors of their
components: we ask that $\Sys{T}$ expose its entire state, which is to say that
$\expose{T}$ is an isomorphism.



\begin{theorem}\label{thm:representables.taut}
Let $\Sys{T}$ be a system in the systems theory $\dd$, and suppose that $\expose{T}$
is an isomorphism. Then the representable lax doubly indexed functor
$\Fun{Behave}_{\Sys{T}}$ is in fact taut. Explicitly, for any lens
$\lens{w^{\sharp}}{w} : \lens{I}{O} \fromto \lens{I'}{O'}$ the natural transformation
  \[
    \begin{tikzcd}
\Cat{Sys}\lens{I}{O} \ar[dd, "{\Cat{Sys}\littlelens{w^{\sharp}}{w}}"'] \ar[rr, "{\Fun{Behave}_{\Sys{T}}^{\littlelens{I}{O}}}"] & & \Cat{Vec}\left( \Cat{Arena}\left(
    \littlelens{\In{T}}{\Out{T}}, \littlelens{I}{O} \right) \right) \ar[dd, "{\Cat{Vec}\left(
  \Cat{Arena}\left( \littlelens{\In{T}}{\Out{T}}, \littlelens{w^{\sharp}}{w}
  \right)\right)}"] \ar[ddll, Rightarrow, "{\Fun{Behave}_{\Sys{T}}^{\littlelens{w^{\sharp}}{w}}}"']\\
 & & \\
\Cat{Sys}\lens{I'}{O'}  \ar[rr, "{\Fun{Behave}_{\Sys{T}}^{\littlelens{B^-}{B^+}} }"']& & \Cat{Vec}\left( \Cat{Arena}\left(
    \littlelens{\In{T}}{\Out{T}}, \littlelens{I}{O} \right) \right) \\
    \end{tikzcd}
\]
is a natural isomorphism.
\end{theorem}

Many of the systems representing sorts of behavior which we saw in
\cref{chapter.3} expose their entire state. For example, the systems $\Sys{Time}$
representing trajectories (\cref{ex.trajectory_as_behavior_discrete}), $\Sys{Fix}$ representing steady
states (\cref{ex.steady_state_as_behavior_discrete}), and $\Sys{Clock}_n$ periodic orbits with periodic parameters (\cref{ex.periodic_orbit_as_behavior}). As examples of
systems which don't expose their entire state, we had the systems which
represent steady looking trajectories and periodic orbits whose parameters
aren't periodic from \cref{ex.find_representatives_discrete}.
\cref{thm:representables.taut} says that for the systems $\Sys{Time}$,
$\Sys{Fix}$, and $\Sys{Clock}_n$, we can recover the behaviors of component
systems from the behaviors of composite systems. As we noted in
\cref{rmk:steady.looking.states.lax}, the same cannot be said for steady looking trajectories.


\begin{proof}[Proof of \cref{thm:representables.taut}]
We recall that for a $\lens{I}{O}$-system $\Sys{S}$, the natural transformation
$\Fun{Behave}_{\Sys{T}}^{\littlelens{w^{\sharp}}{w}}$ goes from the vector of
sets
\begin{align*}
\littlelens{g_{\flat}}{g} : \littlelens{\In{T}}{\Out{T}} \tto \littlelens{I'}{O'}
&\mapsto \left\{    
    \begin{tikzcd}[ampersand replacement = \&]
      \lens{\In{T}}{\Out{T}} \ar[r, shift left, dashed, "\lens{f_{\flat}}{f}"] \ar[r, dashed, shift right] \ar[d, shift right,
      equals] \ar[d, shift left, equals] \&
      \lens{I}{O} \ar[d, shift left, leftarrow,
      "\lens{w^{\sharp}}{w}"] \ar[d, shift right]\\
      \lens{\In{T}}{\Out{T}} \ar[r, shift right, "\lens{g_{\flat}}{g}"'] \ar[r,
      shift left] \& \lens{I'}{O'}
    \end{tikzcd}, \quad
    \begin{tikzcd}[ampersand replacement = \&]
      \lens{\State{T}}{\State{T}} \ar[r, shift left, dashed, "\lens{T\phi}{\phi}"] \ar[r, dashed, shift right] \ar[d, shift right,
      "\lens{\update{T}}{\expose{T}}"'] \ar[d, shift left, leftarrow] \&
      \lens{\State{S}}{\State{S}} \ar[d, shift left, leftarrow,
      "\lens{\update{S}}{\expose{S}}"] \ar[d, shift right]\\
      \lens{\In{T}}{\Out{T}} \ar[r, shift right, "\lens{f_{\flat}}{f}"'] \ar[r,
      shift left] \& \lens{I}{O}
    \end{tikzcd}
\right\}
\end{align*}
to the vector of sets
\[
\littlelens{g_{\flat}}{g} : \littlelens{\In{T}}{\Out{T}} \tto \littlelens{I'}{O'}
\mapsto \left\{  
    \begin{tikzcd}[ampersand replacement = \&]
      \lens{\State{T}}{\State{T}} \ar[r, shift left, dashed, "\lens{T\phi}{\phi}"] \ar[r, dashed, shift right] \ar[d, shift right,
      "\lens{\update{T}}{\expose{T}}"'] \ar[d, shift left, leftarrow] \&
      \lens{\State{S}}{\State{S}} \ar[d, shift left, leftarrow,
      "\lens{\update{S}}{\expose{S}}\then \lens{w^{\sharp}}{w}"] \ar[d, shift right]\\
      \lens{\In{T}}{\Out{T}} \ar[r, shift right, "\lens{g_{\flat}}{g}"'] \ar[r,
      shift left] \& \lens{I'}{O'}
    \end{tikzcd} 
\right\}
\]
The transformation itself is given by vertical composition:  
  \[
\Fun{Behave}_{\Sys{T}}^{\littlelens{w^{\sharp}}{w}}(\Sys{S})_{\littlelens{g_{\flat}}{g}}(\square_{w}, \phi) = \frac{\phi}{\square_w}.
  \]
We'll construct an inverse to this assuming that $\expose{T}$ is an
isomorphism. Suppose we have a square
\[
  \alpha =
    \begin{tikzcd}[ampersand replacement = \&]
      \lens{\State{T}}{\State{T}} \ar[r, shift left,  "\lens{T\phi}{\phi}"] \ar[r,  shift right] \ar[d, shift right,
      "\lens{\update{T}}{\expose{T}}"'] \ar[d, shift left, leftarrow] \&
      \lens{\State{S}}{\State{S}} \ar[d, shift left, leftarrow,
      "\lens{\update{S}}{\expose{S}}\then \lens{w^{\sharp}}{w}"] \ar[d, shift right]\\
      \lens{\In{T}}{\Out{T}} \ar[r, shift right, "\lens{g_{\flat}}{g}"'] \ar[r,
      shift left] \& \lens{I'}{O'}
    \end{tikzcd} 
\]
From this data, we can define a chart
\[
\lens{h_{\flat}}{h} = \lens{g_{\flat} \then
  \expose{T}^{-1\ast}\phi^{\ast}\expose{S}^{\ast}w^{\sharp}}{\expose{T}\inv
  \then \phi \then \expose{S}} : \lens{\In{T}}{\Out{T}} \rightrightarrows \lens{I}{O}.
\]
It isn't obvious that the top composite is well defined since we have $g_{\flat}
: \In{T} \to g^{\ast} I'$ and $\expose{T}^{-1\ast}
\phi^{\ast}\expose{S}^{\ast}w^{\sharp} : \expose{T}^{-1\ast}
\phi^{\ast}\expose{S}^{\ast} w^{\ast} I' \to \expose{T}^{-1\ast}
\phi^{\ast}\expose{S}^{\ast} I$ and the codomain of the first doesn't appear to
be the domain of the second. But the square $\alpha$ tells us that $\phi \then
\expose{S} \then w = \expose{T} \then g$, so we have that
\[
   \expose{T}\inv \then \phi \then \expose{S} \then w = \expose{T} \inv
    \then \expose{T} \then g = g.
  \]
  So the two maps really are composable.

  Next, we note that the following is a square:
  \[
    \square_{h} = \begin{tikzcd}[ampersand replacement = \&]
      \lens{\In{T}}{\Out{T}} \ar[r, shift left, dashed, "{\lens{h_{\flat}}{h}}"] \ar[r, dashed, shift right] \ar[d, shift
right, equals] \ar[d, shift left, equals] \&
      \lens{I}{O} \ar[d, shift left, leftarrow,
      "\lens{w^{\sharp}}{w}"] \ar[d, shift right]\\
      \lens{\In{T}}{\Out{T}} \ar[r, shift right, "\lens{g_{\flat}}{g}"'] \ar[r,
      shift left] \& \lens{I'}{O'}
    \end{tikzcd} 
  \] 
  since
  \begin{align*}
    h \then w &= \expose{T}\inv \then \phi \then \expose{S} \then w \\
              &= \expose{T}\inv \then \expose{T} \then g \\
              &= g &\mbox{and}\\
   h_{\flat} &= g_{\flat} \then h^{\ast} w^{\sharp} &\mbox{, by definition.}
  \end{align*}

 We see that the definition of $\lens{h_{\flat}}{h}$ is basically forced on us
 by the commutation of this diagram. Furthermore, we note that we have a square:
 \[
\beta =    \begin{tikzcd}[ampersand replacement = \&]
      \lens{\State{T}}{\State{T}} \ar[r, shift left,  "\lens{T\phi}{\phi}"] \ar[r,  shift right] \ar[d, shift right,
      "\lens{\update{T}}{\expose{T}}"'] \ar[d, shift left, leftarrow] \&
      \lens{\State{S}}{\State{S}} \ar[d, shift left, leftarrow,
      "\lens{\update{S}}{\expose{S}}"] \ar[d, shift right]\\
      \lens{\In{T}}{\Out{T}} \ar[r, shift right, "\lens{h_{\flat}}{h}"'] \ar[r,
      shift left] \& \lens{I}{O}
    \end{tikzcd} 
\]
by the commutativity of $\alpha$.

Finally, it remains to show that for any $\lens{h_{\flat}}{h}$ fitting into
these two squares $\square_h$ and $\beta$, we have that
\[
\lens{h_{\flat}}{h} = \lens{g_{\flat} \then
  \expose{T}^{-1\ast}\phi^{\ast}\expose{S}^{\ast}w^{\sharp}}{\expose{T}\inv
  \then \phi \then \expose{S}} .
\]
From the bottom of $\beta$, we see that $\expose{T} \then h = \phi \then \expose{S}$, which means that $h = \expose{T}\inv \then \phi \then \expose{S}$ since $\expose{T}$ is an isomorphism. From the top of $\square_h$, we see
exactly that $h_{\flat} = g_{\flat} \then h^{\ast} w^{\sharp}$.
\end{proof}

\begin{example}
In the deterministic systems theory $\determ$, consider the system $\Sys{Time}$ of \cref{ex.trajectory_as_behavior_discrete}:
\[
\lens{t\mapsto t+1}{\id}\colon\lens{\nn}{\nn}\fromto\lens{\{\fun{tick}\}}{\nn}.
\]
This system exposes its entire state since $\expose{Time} = \id$. A behavior of
shape $\Sys{Time}$ is a trajectory. So, by
\cref{thm:representables.taut}, we get a doubly indexed functor:
\[\begin{tikzcd}
	{\Cat{Arena}_{\determ}} \\
	&& {\Cat{Cat}} \\
	{\Cat{Matrix}}
	\arrow[""{name=0, anchor=center, inner sep=0}, "{\Cat{Sys}_{\determ}}", from=1-1,
  to=2-3, bend left = 10]
	\arrow[""{name=1, anchor=center, inner sep=0}, "{\Cat{Vec}}"', from=3-1,
  to=2-3, bend right = 10]
	\arrow["{\Cat{Arena}_{\determ}\left(\littlelens{\ord{1}}{\nn},-\right)}"', from=1-1, to=3-1]
	\arrow["{\Fun{Traj}}"', shorten <=4pt, shorten >=4pt, Rightarrow, from=0, to=1]
\end{tikzcd}\]
For any $\lens{I}{O}$-system $\Sys{S}$, we get a vector of sets 
$$\littlelens{i}{o} \mapsto \Fun{Traj}_{\littlelens{i}{o}}(\Sys{S})$$
sending each chart $\lens{i}{o} : \lens{\ord{1}}{\nn} \rightrightarrows
\lens{I}{O}$ --- which is to say sequences $o : \nn \to O$ and $i : \nn \to I$
of inputs --- to the set of trajectories $s : \nn \to \Sys{S}$ for that chart.
These trajectories are, explicitly, sequences which satisfy the equations 
\begin{align*}
  s_{t + 1} &= \update{S}(s_t, i_t) \\
  \expose{S}(s_t) &= o_t.
\end{align*}

\cref{thm:representables.taut} tells us that trajectories in a composite system
are families of trajectories for each system which agree on all the information
passed between the wires. For example, consider the wiring diagram

\begin{equation}\label{eqn:ex.diagram.traj.comp}
\begin{tikzpicture}[oriented WD]
	\node[bb={1}{2}, fill=blue!10] (A) {$\Sys{S}$};
	\node[bb={2}{1}, below right=-1 and 1 of A, fill=blue!10] (B) {$\Sys{T}$};
	\node[bb={0}{0}, fit={(A) (B)}] (outer) {};
	\node[right=.6 of A_out1] (kill) {$\bullet$};
	\draw (outer.west|-A_in1) -- (A_in1);
	\draw (outer.west|-B_in2) -- (B_in2);
	\draw (A_out1) to node[above, font=\footnotesize] {} (kill.center);
	\draw (A_out2) to (B_in1);
	\draw (B_out1) -- (B_out1-|outer.east);
\end{tikzpicture}
\end{equation}
Let's suppose that all wires carry real numbers. Then this wiring diagram can be represented by the lens
$$\lens{w^{\sharp}}{w} : \lens{\rr}{\rr \times \rr} \otimes \lens{\rr \times
  \rr}{\rr} \fromto \lens{\rr \times \rr}{\rr}$$
given by
\begin{align*}
  w((a, b), c) &= c \\
  w^{\sharp}(((a, b), c), (x, y)) &= (x, (b, y)). 
\end{align*}
\jaz{FINISH THIS.}

\end{example}

\begin{example}\label{ex:trajectories.compositional.behavior}
In a differential systems theory --- for simplicity let's say the Euclidean
differential systems theory $\eucdiff$ --- the system
\[
\Sys{Time} = \lens{1}{\id} : \lens{\rr^1}{\rr^1} \fromto \lens{\rr^0}{\rr^1}
\]
which expresses the differential equation
$$\frac{ds}{dt} = 1$$
represents trajectories (see \cref{ex:diff.doc.time.system}). As this system
exposes its entire state, \cref{thm:representables.taut} gives us a doubly
indexed functor
\[
\begin{tikzcd}
	{\Cat{Arena}_{\eucdiff}} \\
	&& {\Cat{Cat}} \\
	{\Cat{Matrix}}
	\arrow[""{name=0, anchor=center, inner sep=0}, "{\Cat{Sys}_{\eucdiff}}", from=1-1,
  to=2-3, bend left = 10]
	\arrow[""{name=1, anchor=center, inner sep=0}, "{\Cat{Vec}}"', from=3-1,
  to=2-3, bend right = 10]
	\arrow["{\Cat{Arena}_{\determ}\left(\littlelens{\ord{1}}{\nn},-\right)}"', from=1-1, to=3-1]
	\arrow["{\Fun{Traj}}"', shorten <=4pt, shorten >=4pt, Rightarrow, from=0, to=1]
\end{tikzcd}
\]

\end{example}

\end{document}
